{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af2d57c",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [Classification of the Iris dataset with a MLP](#Classification-of-the-Iris-dataset-with-a-MLP)\n",
    "- [Binary classification of the IMDB movie reviews dataset with a MLP](#Binary-classification-of-the-IMDB-movie-reviews-dataset-with-a-MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa3fe4b",
   "metadata": {},
   "source": [
    "# 1  Classification of the Iris dataset with a MLP\n",
    "In this exercise, we will build a small very simple MLP to classify irises into 3 dif-ferent species based on 4 measurements. We will keep this exercise very simple.Some things donotrepresent best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4bce9",
   "metadata": {},
   "source": [
    "## 1.1  Load the Data\n",
    "The iris dataset is built-in intosklearn.datasets. We use `return_X_y=True` to get a numpy array with the features, and a numpy array with the targets.Check the shape of these arrays. They should be`(150, 4)` and `(150, )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b616c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X # Features\n",
    "y # labels\n",
    "(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080af7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb3c5d1",
   "metadata": {},
   "source": [
    "## 1.2  Build a MLP\n",
    "We want to build an MLP consisting of:\n",
    "- An input layer with the correct number of neurons. The name of the layerisinput. How many neurons do we need in the input layer?\n",
    "- One hidden layer with 5 neurons using the *ReLU£* activation function. Thename of the layer ishidden\n",
    "- One output layer with the correct number of neurons and the correct activation function for a classification problem. The name of the layer is output.\n",
    "\n",
    "Follow the steps below:\n",
    "\n",
    "1. Take a look at the examples on https://keras.io/api/models/sequential/.\n",
    "2. An example on how to pass the activation function via the string identifier: https://keras.io/api/layers/activations/.\n",
    "3. Write similar code to create the model.\n",
    "4. Very often, it is convenient if we can easily recreate a model using a smallfunctionget_model. Rewrite the previous code to a small functionget_modelthat returns the model as described above. Take a look at https://keras.io/api/models/model/#with-the-sequential-class to see an example.\n",
    "5. Create the model using the functionget_model.\n",
    "6. Use thesummarymethod of the model to verify that your model has 43 parameters.\n",
    "7. Convince yourself that you understand where this number comes from!Making a simple sketch of the model can be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf46a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# dir(model) -> functies bekijken van model\n",
    "\n",
    "#? https://keras.io/api/layers/core_layers/input/\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(4,), name=\"input\")) #* input: 1 bij 4\n",
    "    model.add(keras.layers.Dense(units=5, activation=\"relu\", name=\"hidden\")) # W^[1] = 4 bij 5 -> [4,5]\n",
    "    model.add(keras.layers.Dense(units=3, activation=\"softmax\", name=\"output\")) # W^[2] = 5 bij 3 -> [5,3]\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306bddf",
   "metadata": {},
   "source": [
    "## 1.3  Compile the Model\n",
    "Compile the model with the following options (example on https://keras.io/api/models/model_training_apis/):\n",
    "- Use stochastic gradient descent with all the default parameters as the optimizer.\n",
    "- Specify the correct loss for a multi-class classification problem, where eachinstance belongs to exactly one class. Take into account the shape of thetargets above which is (150, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00441b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#* https://keras.io/api/models/model_training_apis/\n",
    "#* https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class\n",
    "model.compile(optimizer=\"sgd\", loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4392c",
   "metadata": {},
   "source": [
    "# 1.4  Train the Model\n",
    "Train the model for 20 epochs (example on\n",
    "https://keras.io/api/models/model_training_apis/). Because we have such a small dataset we will use abatch size of 8 so that we have a reasonable number of updates per epoch.\n",
    "\n",
    "Note: since we are not using any validation data we have no way of knowing whether the model is overfitting or not. Don’t do this in practice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecbaa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=10,batch_size=8)\n",
    "#? Epoche is aantal keer dat je over de hele dataset gaat (150 samples)\n",
    "#? Batch size is aantal groepjes in een epoche en één epoch is dan alle samples (batches) gezien hebben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb8822e",
   "metadata": {},
   "source": [
    "## 1.5  Emulate the Calculations of the Model\n",
    "This step is not necessary in practice. We include it here for a better under-standing of what is going on.First, compute the result of the model (the MLP) on a small batch.\n",
    "\n",
    "1. Create a tensor called `X_batch` which consists of the first two trainingexamples. Use the slice operator. What is the shape of this tensor?\n",
    "\n",
    "2. Call the model with `X_batch` as the input. Call the resulty_batch_pred.What is the shape of this tensor? What does each dimension mean\n",
    "3.  Use a function ofkeras.opsto verify that the sum of each row is equalto one.Now, emulate these calculations “by hand” and verify that you get the sameresults.\n",
    "   \n",
    "   a.  First, extract the weights of the hidden layer and store them as W1 and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume\"model\"is the name as signed to the MLP\n",
    "W_hidden, bias_hidden = model.get_layer(\"hidden\").get_weights()\n",
    "print(\"hidden\", W_hidden.shape, bias_hidden.shape)\n",
    "W_output, bias_output = model.get_layer(\"output\").get_weights()\n",
    "print(\"output\", W_output.shape, bias_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca1fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = X[:2]\n",
    "print(X_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7029e411",
   "metadata": {},
   "source": [
    "Do the same for the weights of the output layer.\n",
    "b. Verify the shape of these 4 tensors. Make sure that you understand these.\n",
    "c. Complete the following code, using only methods from `keras.ops`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c066e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = keras.ops.matmul(X_batch, W_hidden) + bias_hidden\n",
    "a1 = keras.ops.relu(z1)   # apply relu to z1\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = keras.ops.matmul(a1, W_output) + bias_output  # linear transformation of output layer\n",
    "a2 = keras.ops.softmax(z2)\n",
    "print(a2)\n",
    "y_batch_pred_2 = keras.ops.softmax(z2)  # apply appropriate activation function to z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#? Model is het volledig bereken\n",
    "model(X_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399d0d8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90c791a7",
   "metadata": {},
   "source": [
    "# 2  Binary Classification with a MLP\n",
    "In this exercise, we are going to classify (preprocessed) movie reviews as eitherpositive or negative. We will use the built-in IMDB (Internet Movie Database)Keras dataset for this\n",
    "## 2.1  Load the Data\n",
    "1. Use `keras.datasets.imdb.load_data()` to easily download the IMDBdataset.\n",
    "2. Limit the vocabulary to the 10000 most frequent words, by using thenum_wordsargument. See `https://keras.io/api/datasets/imdb/for` information on how to use this function. A possible way of calling this function is: `(train_data, train_labels), (test_data, test_labels) = YOUR CODE HERE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d5974d",
   "metadata": {},
   "source": [
    "3. Check that both `train_data` and `test_data` contain 25000 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c108ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape, train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff446f",
   "metadata": {},
   "source": [
    "4. Print the features of the first training example. You should see somethinglike: `[1, 14, 22, 16, ..., 178, 32]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c53e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b77bb4",
   "metadata": {},
   "source": [
    "5. Hence, each example is a list of integers. You can use the function in Figure 1 to convert such a list of integers back into English text. This way you can get a feel of what the review is like, but this is not what we will feed to the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def convert_to_english(list_of_integers):\n",
    "    word_index = keras.datasets.imdb.get_word_index() # reverse the wordindex\n",
    "    rv_word_index = {idx : word for(word, idx) in word_index.items() }\n",
    "    # map each integer to a word and join all words together\n",
    "    # Index 0,1 and 2 are reserved for 'padding','start of sequence '&' unknown'\n",
    "    return \" \".join(rv_word_index.get(idx - 3,\"?\")for idx in list_of_integers)\n",
    "convert_to_english(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ff8e0",
   "metadata": {},
   "source": [
    "## 2.2  Convert the Data \n",
    "It is not very convenient for a neural network to ingest list of integers. Instead,we will use `multi-hot encoding` to convert the lists of integers into vectors of0s and 1s\n",
    "1. Write a function `convert_to_multi_hot(sequences, dimension)` that takes a numpy array of sequences (i.e. lists of integers) and returnsa numpy array of `shape(len(sequences), dimension)` where each row is a multi-hot encoded vector of length dimension. You can write thisfunction using “ordinary” loops. Later, we will see how you can make thistype of function more eﬀicient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_multi_hot(sequences, dimension):\n",
    "    # Create numpy array of the correct shape and datatype filled with zeros.\n",
    "    output = np.zeros(shape=(sequences.shape[0], dimension), dtype=np.float32)\n",
    "    for i in range(sequences.shape[0]):\n",
    "        for j in sequences[i]:\n",
    "            output[i,j] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e2cc9",
   "metadata": {},
   "source": [
    "2. Convert the training and test data to multi-hot encoded vectors. Use adimension of 10000. (Since we used 10000 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da49615",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = convert_to_multi_hot(train_data, dimension=10_000)\n",
    "X_test = convert_to_multi_hot(test_data, dimension=10_000)\n",
    "#Renamethelabels\n",
    "y_train = train_labels\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fdff2f",
   "metadata": {},
   "source": [
    "3. We will also need validation data. We will use the first 10000 examplesfrom the test data as our validation data. The last 15000 examples will beused as our test data. Write code to create the validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[:10000]\n",
    "y_val = y_test[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752cfb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[:10000]\n",
    "y_test = y_test[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562ccd2",
   "metadata": {},
   "source": [
    "## 2.3  Build a Model\n",
    "1. Build a model using the Sequential API. Use the following architecture:\n",
    "   - Use theInputfunction/object to indicate the shape (excluding thebatch dimension) and optionally the data type of the input tensors.\n",
    "   - A Denselayer with 16 units and the ReLU activation function.\n",
    "   - A Dense layer with 16 units and the ReLU activation function.\n",
    "   - ADenseoutput layer.\n",
    "     - How many units should this layer have?\n",
    "     - What is the most appropriate activation function for this layer,given that we are doing binary classification?\n",
    "  2. Write a functionget_model()that returns this model. Ask for thesummaryof the returned model. You should see that the model has 160305 train-able parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6224653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() -> keras.Sequential:\n",
    "    \"\"\"Returns a compiled keras Sequential model\"\"\"\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.Input(shape=[10000,]))\n",
    "    model.add(keras.layers.Dense(units=16,activation=\"relu\",name= \"hidden_1\"))\n",
    "    model.add(keras.layers.Dense(units=16,activation=\"relu\",name= \"hidden_2\"))\n",
    "\n",
    "    model.add(keras.layers.Dense(units=1,activation=\"sigmoid\",name= \"output\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec95ca3",
   "metadata": {},
   "source": [
    "## 2.4  Compile the Model\n",
    "1. Compile the model.\n",
    "   - Use rmsprop as the optimizer with all the default parameter settings.\n",
    "   - Specify the correct loss for a binary classification problem.\n",
    "   - Track the accuracy metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecc039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452916c2",
   "metadata": {},
   "source": [
    "## 2.5  Train the Model\n",
    "1. Train the model.\n",
    "   - Train it for 20 epochs.\n",
    "   - Use a batch size of 512.\n",
    "   - Be sure to use the validation data.\n",
    "2. Use the history object returned by thefitmethod to plot the learningcurves. You can use the code in Figure 2 to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7583344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curves(history):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for key, style in zip(history.history, [\"r-o\",\"r-*\",\"b-o\",\"b-*\"]):\n",
    "        epochs = np.array(history.epoch)\n",
    "        plt.plot(epochs + 1, history.history[key], style, label=key)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.axis([1,len(history.history['loss']), 0., 1])\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da5e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f10e3f",
   "metadata": {},
   "source": [
    "3. You should notice that the model is overfitting.\n",
    "4. Initialize and compile the model again, but train for fewer epochs, so thatthe model does not overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b226c2d",
   "metadata": {},
   "source": [
    "## 2.6  Evaluate the Model\n",
    "1. Use the evaluatemethod to evaluate the model on the test set.\n",
    "2. What is the performance of the model on the test set1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09a1e71",
   "metadata": {},
   "source": [
    "# 3  MNIST with a Deep MLP\n",
    "This exercise is based on exercise 10 from chapter 10 of the book “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron. However, it contains more detailed instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cbef1d",
   "metadata": {},
   "source": [
    "## 3.1  Load and Preprocess the MNIST dataset\n",
    "1. Use `keras.datasets.mnist.load_data()` to easily download the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff0fbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       " array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8),\n",
       " array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       " array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=uint8))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train[:10], y_train[:10], X_test[:10], y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee5a698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[2].shape:  (28, 28)\n",
      "y_train:  (60000,)\n",
      "X_train[0].shape:  (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train[2].shape: \", X_train[2].shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_train[0].shape: \", X_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d355148b",
   "metadata": {},
   "source": [
    "2. Use the last 10000 images of the training set as your validation set. This will give you 50000 training images, 10000 validation images, and 10000 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcad3e1",
   "metadata": {},
   "source": [
    "3. The pixel values are stored as integers (from 0 to 255). Convert them to floats between 0.0 and 1.0(by dividing by 255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ee92a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (30000, 784) (30000,)\n",
      "Validation data: (10000, 784) (10000,)\n",
      "Test data: (10000, 784) (10000,)\n",
      "---\n",
      "y_val.shape: (10000,)\n",
      "X_val.shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_val = X_train[-10_000:] / 255.0\n",
    "y_val = y_train[-10_000:]\n",
    "\n",
    "X_train = X_train[:-10_000:] / 255.0\n",
    "y_train = y_train[:-10_000:]\n",
    "\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print(\"Training data:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation data:\", X_val.shape, y_val.shape)\n",
    "print(\"Test data:\", X_test.shape, y_test.shape)\n",
    "print(\"---\")\n",
    "print(\"y_val.shape:\", y_val.shape)\n",
    "print(\"X_val.shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46c93933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 6.03086294e-08, 1.20617259e-07, 1.80925888e-07,\n",
       "       2.41234518e-07, 3.01543147e-07, 3.61851776e-07, 4.22160406e-07,\n",
       "       4.82469035e-07, 5.42777665e-07, 6.03086294e-07, 6.63394924e-07,\n",
       "       7.23703553e-07, 7.84012182e-07, 8.44320812e-07, 9.04629441e-07,\n",
       "       9.64938071e-07, 1.02524670e-06, 1.08555533e-06, 1.14586396e-06,\n",
       "       1.20617259e-06, 1.26648122e-06, 1.32678985e-06, 1.38709848e-06,\n",
       "       1.44740711e-06, 1.50771574e-06, 1.56802436e-06, 1.62833299e-06,\n",
       "       1.68864162e-06, 1.74895025e-06, 1.80925888e-06, 1.86956751e-06,\n",
       "       1.92987614e-06, 1.99018477e-06, 2.05049340e-06, 2.11080203e-06,\n",
       "       2.17111066e-06, 2.23141929e-06, 2.29172792e-06, 2.35203655e-06,\n",
       "       2.41234518e-06, 2.47265381e-06, 2.53296244e-06, 2.59327106e-06,\n",
       "       2.65357969e-06, 2.71388832e-06, 2.77419695e-06, 2.83450558e-06,\n",
       "       2.89481421e-06, 2.95512284e-06, 3.01543147e-06, 3.07574010e-06,\n",
       "       3.13604873e-06, 3.19635736e-06, 3.25666599e-06, 3.31697462e-06,\n",
       "       3.37728325e-06, 3.43759188e-06, 3.49790051e-06, 3.55820914e-06,\n",
       "       3.61851776e-06, 3.67882639e-06, 3.73913502e-06, 3.79944365e-06,\n",
       "       3.85975228e-06, 3.92006091e-06, 3.98036954e-06, 4.04067817e-06,\n",
       "       4.10098680e-06, 4.16129543e-06, 4.22160406e-06, 4.28191269e-06,\n",
       "       4.34222132e-06, 4.40252995e-06, 4.46283858e-06, 4.52314721e-06,\n",
       "       4.58345584e-06, 4.64376446e-06, 4.70407309e-06, 4.76438172e-06,\n",
       "       4.82469035e-06, 4.88499898e-06, 4.94530761e-06, 5.00561624e-06,\n",
       "       5.06592487e-06, 5.12623350e-06, 5.18654213e-06, 5.24685076e-06,\n",
       "       5.30715939e-06, 5.36746802e-06, 5.42777665e-06, 5.48808528e-06,\n",
       "       5.54839391e-06, 5.60870254e-06, 5.66901116e-06, 5.72931979e-06,\n",
       "       5.78962842e-06, 5.84993705e-06, 5.91024568e-06, 5.97055431e-06,\n",
       "       6.03086294e-06, 6.09117157e-06, 6.15148020e-06, 6.21178883e-06,\n",
       "       6.27209746e-06, 6.33240609e-06, 6.39271472e-06, 6.45302335e-06,\n",
       "       6.51333198e-06, 6.57364061e-06, 6.63394924e-06, 6.69425786e-06,\n",
       "       6.75456649e-06, 6.81487512e-06, 6.87518375e-06, 6.93549238e-06,\n",
       "       6.99580101e-06, 7.05610964e-06, 7.11641827e-06, 7.17672690e-06,\n",
       "       7.23703553e-06, 7.29734416e-06, 7.35765279e-06, 7.41796142e-06,\n",
       "       7.47827005e-06, 7.53857868e-06, 7.59888731e-06, 7.65919594e-06,\n",
       "       7.71950456e-06, 7.77981319e-06, 7.84012182e-06, 7.90043045e-06,\n",
       "       7.96073908e-06, 8.02104771e-06, 8.08135634e-06, 8.14166497e-06,\n",
       "       8.20197360e-06, 8.26228223e-06, 8.32259086e-06, 8.38289949e-06,\n",
       "       8.44320812e-06, 8.50351675e-06, 8.56382538e-06, 8.62413401e-06,\n",
       "       8.68444264e-06, 8.74475126e-06, 8.80505989e-06, 8.86536852e-06,\n",
       "       8.92567715e-06, 8.98598578e-06, 9.04629441e-06, 9.10660304e-06,\n",
       "       9.16691167e-06, 9.22722030e-06, 9.28752893e-06, 9.34783756e-06,\n",
       "       9.40814619e-06, 9.46845482e-06, 9.52876345e-06, 9.58907208e-06,\n",
       "       9.64938071e-06, 9.70968934e-06, 9.76999796e-06, 9.83030659e-06,\n",
       "       9.89061522e-06, 9.95092385e-06, 1.00112325e-05, 1.00715411e-05,\n",
       "       1.01318497e-05, 1.01921584e-05, 1.02524670e-05, 1.03127756e-05,\n",
       "       1.03730843e-05, 1.04333929e-05, 1.04937015e-05, 1.05540101e-05,\n",
       "       1.06143188e-05, 1.06746274e-05, 1.07349360e-05, 1.07952447e-05,\n",
       "       1.08555533e-05, 1.09158619e-05, 1.09761706e-05, 1.10364792e-05,\n",
       "       1.10967878e-05, 1.11570964e-05, 1.12174051e-05, 1.12777137e-05,\n",
       "       1.13380223e-05, 1.13983310e-05, 1.14586396e-05, 1.15189482e-05,\n",
       "       1.15792568e-05, 1.16395655e-05, 1.16998741e-05, 1.17601827e-05,\n",
       "       1.18204914e-05, 1.18808000e-05, 1.19411086e-05, 1.20014173e-05,\n",
       "       1.20617259e-05, 1.21220345e-05, 1.21823431e-05, 1.22426518e-05,\n",
       "       1.23029604e-05, 1.23632690e-05, 1.24235777e-05, 1.24838863e-05,\n",
       "       1.25441949e-05, 1.26045035e-05, 1.26648122e-05, 1.27251208e-05,\n",
       "       1.27854294e-05, 1.28457381e-05, 1.29060467e-05, 1.29663553e-05,\n",
       "       1.30266640e-05, 1.30869726e-05, 1.31472812e-05, 1.32075898e-05,\n",
       "       1.32678985e-05, 1.33282071e-05, 1.33885157e-05, 1.34488244e-05,\n",
       "       1.35091330e-05, 1.35694416e-05, 1.36297502e-05, 1.36900589e-05,\n",
       "       1.37503675e-05, 1.38106761e-05, 1.38709848e-05, 1.39312934e-05,\n",
       "       1.39916020e-05, 1.40519107e-05, 1.41122193e-05, 1.41725279e-05,\n",
       "       1.42328365e-05, 1.42931452e-05, 1.43534538e-05, 1.44137624e-05,\n",
       "       1.44740711e-05, 1.45343797e-05, 1.45946883e-05, 1.46549969e-05,\n",
       "       1.47153056e-05, 1.47756142e-05, 1.48359228e-05, 1.48962315e-05,\n",
       "       1.49565401e-05, 1.50168487e-05, 1.50771574e-05, 1.51374660e-05,\n",
       "       1.51977746e-05, 1.52580832e-05, 1.53183919e-05, 1.53787005e-05])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145b5a2",
   "metadata": {},
   "source": [
    "4. Reshape the tensors so that they have rank 2 instead of rank 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ba68f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val.shape: (10000, 784)\n",
      "X_train.shape: (30000, 784)\n",
      "X_test.shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_val = X_val.reshape(-1, 28 * 28) #? 28 * 28 is gehardcodeerd, normaal zou je dit dynamisch doen\n",
    "X_train = X_train.reshape((-1, 28 * 28)) #? -1 betekent dat numpy zelf moet uitrekenen hoeveel rijen er moeten komen\n",
    "X_test = X_test.reshape((-1, 28 * 28)) #? 28 * 28 is de breedte van een plaatje\n",
    "\n",
    "print(\"X_val.shape:\", X_val.shape)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce29701b",
   "metadata": {},
   "source": [
    "# 3.2  Build a MLP\n",
    "1. Use the Sequential API to build to build a model with two hidden layers and one output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f294316",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 28*28\n",
    "def get_model() -> keras.Sequential:\n",
    "    \"\"\"Model with two hidden layers and one output layer\n",
    "\n",
    "    Returns:\n",
    "        keras.Sequential: Model\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(dims,)), #? meegeven als een tuple\n",
    "        keras.layers.Dense(units=300, activation=\"relu\"),\n",
    "        keras.layers.Dense(units=100, activation=\"relu\"),\n",
    "\n",
    "        keras.layers.Dense(units=10, activation=\"softmax\") #? Multiclass, dus softmax\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fff838cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83564b",
   "metadata": {},
   "source": [
    "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ dense (Dense)                   │ (None, 300)            │       235,500 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_1 (Dense)                 │ (None, 100)            │        30,100 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense_2 (Dense)                 │ (None, 10)             │         1,010 │"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fca64e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params 1st dense layer: 265500\n",
      "Params 2nd dense layer: 30100\n",
      "Params output layer: 1010\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#* inputs +\n",
    "params_1 = 884 * 300 + 300\n",
    "params_2 = 300 * 100 + 100\n",
    "params_3 = 100 * 10 + 10\n",
    "\n",
    "print(\"Params 1st dense layer: \" + str(params_1))\n",
    "print(\"Params 2nd dense layer: \" + str(params_2))\n",
    "print(\"Params output layer: \" + str(params_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa132d",
   "metadata": {},
   "source": [
    "2. Use the ReLU activation function for the hidden layers (with 300 and 100 units each) and the appropriate activation function and number of units for the output layer, given that we are doing multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4b28092",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5843be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1099 - loss: 2.3025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.1133 - loss: 2.3023 - val_accuracy: 0.1140 - val_loss: 2.3021\n",
      "Epoch 2/30\n",
      "\u001b[1m112/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1133 - loss: 2.3021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3019 - val_accuracy: 0.1140 - val_loss: 2.3018\n",
      "Epoch 3/30\n",
      "\u001b[1m113/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1158 - loss: 2.3016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3016 - val_accuracy: 0.1140 - val_loss: 2.3015\n",
      "Epoch 4/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1162 - loss: 2.3011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3014 - val_accuracy: 0.1140 - val_loss: 2.3014\n",
      "Epoch 5/30\n",
      "\u001b[1m113/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1115 - loss: 2.3014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1141 - loss: 2.3012 - val_accuracy: 0.1140 - val_loss: 2.3013\n",
      "Epoch 6/30\n",
      "\u001b[1m112/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1111 - loss: 2.3011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1141 - loss: 2.3011 - val_accuracy: 0.1140 - val_loss: 2.3012\n",
      "Epoch 7/30\n",
      "\u001b[1m115/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1138 - loss: 2.3012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1141 - loss: 2.3011 - val_accuracy: 0.1140 - val_loss: 2.3012\n",
      "Epoch 8/30\n",
      "\u001b[1m115/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1144 - loss: 2.3007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3010 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 9/30\n",
      "\u001b[1m110/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1135 - loss: 2.3007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3010 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 10/30\n",
      "\u001b[1m115/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1125 - loss: 2.3010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1141 - loss: 2.3010 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 11/30\n",
      "\u001b[1m114/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1144 - loss: 2.3009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3010 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 12/30\n",
      "\u001b[1m114/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1175 - loss: 2.3004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1141 - loss: 2.3010 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 13/30\n",
      "\u001b[1m117/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1126 - loss: 2.3014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 14/30\n",
      "\u001b[1m113/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1139 - loss: 2.3012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 15/30\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1141 - loss: 2.3010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 16/30\n",
      "\u001b[1m117/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1157 - loss: 2.3008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 17/30\n",
      "\u001b[1m117/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1123 - loss: 2.3012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 18/30\n",
      "\u001b[1m115/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1128 - loss: 2.3015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 19/30\n",
      "\u001b[1m112/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1178 - loss: 2.3003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 20/30\n",
      "\u001b[1m112/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1123 - loss: 2.3011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 21/30\n",
      "\u001b[1m112/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1139 - loss: 2.3008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 22/30\n",
      "\u001b[1m112/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1163 - loss: 2.3007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 23/30\n",
      "\u001b[1m115/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1161 - loss: 2.3003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 24/30\n",
      "\u001b[1m116/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1132 - loss: 2.3012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 25/30\n",
      "\u001b[1m114/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1141 - loss: 2.3010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n",
      "Epoch 26/30\n",
      "\u001b[1m115/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1149 - loss: 2.3006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 2.3009 - val_accuracy: 0.1140 - val_loss: 2.3011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1755a0750>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ! https://keras.io/api/callbacks/early_stopping/\n",
    "#* validation loss gaat bepalen of je bent aan het overfitten of niet\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5\n",
    ")\n",
    "#! https://keras.io/api/callbacks/tensorboard/\n",
    "#* TensorBoard is een tool om je model te visualiseren\n",
    "tensorboard_logging = keras.callbacks.TensorBoard()\n",
    "\n",
    "#! https://keras.io/api/callbacks/model_checkpoint/\n",
    "#* ModelCheckpoint slaat je model op tijdens het trainen\n",
    "checkpoint_path = \"mnist_model.h5\"\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train,\n",
    "          validation_data=(X_val,y_val),\n",
    "          batch_size=256,\n",
    "          epochs=30,\n",
    "          callbacks=[early_stopping, tensorboard_logging, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4bffdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curves(history):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for key, style in zip(history.history, [\"r-o\",\"r-*\",\"b-o\",\"b-*\"]):\n",
    "        epochs = np.array(history.epoch)\n",
    "        plt.plot(epochs + 1, history.history[key], style, label=key)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.axis([1,len(history.history['loss']), 0., 1])\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid()\n",
    "plot_learning_curves(model.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91884b87",
   "metadata": {},
   "source": [
    "3. Create a function `get_model()`that returns this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca31570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
