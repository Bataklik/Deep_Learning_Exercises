{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3cf6119",
   "metadata": {},
   "source": [
    "# Praktische vragen Deep Learning\n",
    "\n",
    "Sabine De Vreese, Stijn Lievens en Simon De Gheselle\n",
    "\n",
    "29 september 2025\n",
    "\n",
    "## 1  Practice with `tf.data.Dataset`\n",
    "### 1.1  Commonly used operations\n",
    "In this exercise we will practice some commonly used operations oftf.data.Datasetobjects.We start with a (small) Dataset object where each item contains 4 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "# Create list of tuples to beconvertedintoDatasetobject\n",
    "data = [(i, i+1, i+2, 100 + i)for i in range(20)]\n",
    "ds = tf.data.Dataset.from_tensor_slices(data)\n",
    "for item in ds.take(2):\n",
    "    print(item)\n",
    "# Output:\n",
    "# tf.Tensor((0, 1, 2, 100), shape=(4,), dtype=int32)\n",
    "# tf.Tensor((1, 2, 3, 101), shape=(4,), dtype=int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6847b",
   "metadata": {},
   "source": [
    "1. Create a Dataset where each item is a `tuple(X, y)`, where y is the last element of each item in ds.\n",
    "yields:\n",
    "```python\n",
    "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 2], dtype=int32)>,<tf.Tensor: shape=(), dtype=int32, numpy=100>)(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>,<tf.Tensor: shape=(), dtype=int32, numpy=101>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = ds.map(lambda e: (e[:3],e[3]))\n",
    "# ds1 = ds.map(lambda e: (e[:-1],e[-1]))\n",
    "\n",
    "for item in ds1.take(2):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a88581b",
   "metadata": {},
   "source": [
    "2.Starting from ds only keep those items where the sum of the first threeelements is a multiple of 4. Use methods from `keras.ops` to achieve this.\n",
    "\n",
    "yields\n",
    "```python\n",
    "tf.Tensor([  3   4   5 103], shape=(4,), dtype=int32)tf.Tensor([  7   8   9 107], shape=(4,), dtype=int32)tf.Tensor([ 11  12  13 111], shape=(4,), dtype=int32)tf.Tensor([ 15  16  17 115], shape=(4,), dtype=int32)tf.Tensor([ 19  20  21 119], shape=(4,), dtype=int32\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = ds.filter(lambda e: ks.ops.mod(\n",
    "    ks.ops.sum(e[:3]),4) == 0)\n",
    "for item in ds2:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d94372",
   "metadata": {},
   "source": [
    "3.  -   (a) Write a method `normalise(x)` that takes a batch of elements x as input where x has shape(batch_size, num_features). The return value is such that each feature (i.e. each column of x) has mean zero and standard deviation equal to one. Use methods from keras.ops.\n",
    "\n",
    "    -   (b)Transform the original datasetdsby taking the following steps:\n",
    "        -   Cast the tensors totf.float 32 tensors.\n",
    "        -   Shuffle the dataset. Make sure that the buffer size is large enoughto shuffle the complete dataset, and use seed=42 for reproducibility.\n",
    "        -   Create batches of exactly 8 elements each.\n",
    "        -   Normalise each batch using the method normalise you just wrote\n",
    "\n",
    "yields:\n",
    "\n",
    "```python\n",
    "tf.Tensor([[-0.47733918 -0.47733918 -0.47733918 -0.47733918][ 1.2028948   1.2028948   1.2028948   1.2028948 ]..... (some rows removed)[ 0.2864035   0.2864035   0.2864035   0.2864035 ][-0.9355848  -0.9355848  -0.9355848  -0.9355848 ]], shape=(8, 4), dtype=float32)tf.Tensor([[-0.25607374 -0.25607374 -0.25607374 -0.25607374][ 1.5364425   1.5364425   1.5364425   1.5364425 ]..... (some rows removed)[-0.5121475  -0.5121475  -0.5121475  -0.5121475 ][ 1.2803687   1.2803687   1.2803687   1.2803687 ]], shape=(8, 4), dtype=float32)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x):\n",
    "    mu = ks.ops.mean(x,axis=0)\n",
    "    sigma = ks.ops.std(x,axis=0)\n",
    "    return (x-mu)/sigma\n",
    "\n",
    "ds3 = ds.map(lambda e: tf.cast(e,tf.float32)).shuffle(ds.cardinality(),seed=42).batch(8).map(lambda b : normalise(b))\n",
    "for item in ds3:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57322144",
   "metadata": {},
   "source": [
    "Start with a Dataset consisting of [1,2,...,10]. Apply `create_ds` to each element of this Dataset. You get a Dataset where each item itself is a Dataset! Make sure you understand the output of the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_ds(i):\n",
    "    i = tf.cast(i,tf.int64)\n",
    "    return tf.data.Dataset.range(i)\n",
    "\n",
    "ds_of_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices([i for i in range(1,11)])\n",
    "    .map(create_ds)\n",
    "    )\n",
    "\n",
    "for ds in ds_of_ds:\n",
    "    print(f\"{type(ds)},length={len(ds)}\")\n",
    "    for item in ds:\n",
    "        print(item.numpy(), end=\"\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec9c4d4",
   "metadata": {},
   "source": [
    "If you apply flat_map instead of map, the elements of the inner Dataset are strung together to form a Dataset of integers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c23642",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_ds = (tf.data.Dataset.from_tensor_slices(\n",
    "    [i for i in range(1,11)])\n",
    "    .flat_map(create_ds)\n",
    "    )\n",
    "\n",
    "# YOUR CODE HERE TO PRINT THE CONTENTS OF THIS DATASET\n",
    "for flat in flat_ds:\n",
    "    print(flat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a6f66",
   "metadata": {},
   "source": [
    "Finally, replace flat_map(create_ds) by interleave(create_ds, cycle_length=2) and observe the difference in output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_ds = (tf.data.Dataset.from_tensor_slices(\n",
    "    [i for i in range(1,11)])\n",
    "    .interleave(create_ds,cycle_length=2)\n",
    "    )\n",
    "\n",
    "# YOUR CODE HERE TO PRINT THE CONTENTS OF THIS DATASET\n",
    "for flat in flat_ds:\n",
    "    print(flat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad1a4fb",
   "metadata": {},
   "source": [
    "\n",
    "```text\n",
    "Zakje1: [0]\n",
    "Zakje2: [0, 1]\n",
    "Zakje3: [0, 1, 2]\n",
    "\n",
    "Flatmap:\n",
    "Zakje1 -> 0\n",
    "Zakje2 -> 0 1\n",
    "Zakje3 -> 0 1 2\n",
    "Interleave (cycle_length=3):\n",
    "Zakje1 -> 0\n",
    "Zakje2 -> 0\n",
    "Zakje3 -> 0\n",
    "\n",
    "Zakje1 -> 1\n",
    "Zakje2 -> 1\n",
    "Zakje3 -> 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644e086",
   "metadata": {},
   "source": [
    "## 2  IMDB Movie Reviews (Bis)\n",
    "In chapter 10, we already used thepreprocessedIMDB movie reviews dataset.In this exercise, we are going to use therawIMDB movie reviews dataset(which is more representative of real world problems), and build a binary classification model. We will use the keras preprocessing layers, as well as the tf.data.Dataset API.\n",
    "\n",
    "This exercise is similar to, but not exactly the same as, exercise 10 in chapter 13 of the book.\n",
    "\n",
    "### 2.1  Download the dataset\n",
    "Download the dataset from the URL https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz using the keras.utils.get_file utility function. Use the appropriate arguments toget_fileso that:\n",
    "- the downloaded file is unzipped and untarred\n",
    "- the file is stored in the current directory (i.e. the directory where you are running the notebook)\n",
    "\n",
    "Check that the file has been downloaded correctly by verifying that you have a directory called `datasets/aclImdb` in the current directory. This directory should contain the *train* and *test* subdirectories. Each of these directories in turn should contain a pos and neg subdirectory, which in turn contain the actualreviews. You can see the resulting directory structure in Figure1.\n",
    "\n",
    "Note: there are other files and directories present, but we are not going to usethose. Also note that you can use!lsfrom within the notebook (if the underlying operating system understands thelscommand.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random as rnd\n",
    "\n",
    "URL = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "IMDB_ds = ks.utils.get_file(origin=URL,\n",
    "                            fname=\"aclImdb.tar.gz\",\n",
    "                            extract=True,\n",
    "                            cache_dir=\"datasets\",\n",
    "                            cache_subdir=\"\")\n",
    "if os.path.exists(\"datasets/aclImdb_extracted/aclImdb\"):\n",
    "    shutil.move(\"datasets/aclImdb_extracted/aclImdb\",\"datasets/aclImdb\")\n",
    "    shutil.rmtree(\"datasets/aclImdb_extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021dec5b",
   "metadata": {},
   "source": [
    "## 2.2  Create a Validation Directory\n",
    "The dataset as downloaded contains 25000 train and 25000 test examples, with 12500 positive and negative reviews in each set. We are going to use all 25000 examples for training, but we are going to use 15000 of the examples in the test directory for validation. To be more specific, we are going to use 7500 positive and 7500 negative (test) reviews for validation.\n",
    "\n",
    "Note: you could do this outside of Python, but we are going to use Python in this exercise, so that the notebook is fully self contained.\n",
    "\n",
    "- Use `os.makedir` to create directories called val/neg and val/pos next to the existing train and test directories.\n",
    "- Use `os.listdir` to get the list of files in the `test/neg` directory. Use `random.shuffle` to shuffle this list. Use `shutil.move` to move the first 7500 files to the val/neg directory.\n",
    "- Do the same for the `test/pos` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565e6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_PATH = \"./datasets/aclImdb/validation\"\n",
    "TRAIN_PATH = \"./datasets/aclImdb/train\"\n",
    "TEST_PATH = \"./datasets/aclImdb/test\"\n",
    "POS_DIR = \"/pos\"\n",
    "NEG_DIR = \"/neg\"\n",
    "\n",
    "if not os.path.exists(VAL_PATH):\n",
    "    os.mkdir(VAL_PATH)\n",
    "\n",
    "test_files_pos = os.listdir(TEST_PATH+POS_DIR)\n",
    "rnd.shuffle(test_files_pos)\n",
    "test_files_pos = test_files_pos[:7500]\n",
    "\n",
    "if not os.path.exists(VAL_PATH + POS_DIR):\n",
    "    os.mkdir(VAL_PATH + POS_DIR)\n",
    "\n",
    "for f_pos in test_files_pos:\n",
    "    shutil.move(os.path.join(TEST_PATH+POS_DIR,f_pos), os.path.join(VAL_PATH + POS_DIR,f_pos))\n",
    "\n",
    "test_files_neg = os.listdir(TEST_PATH+NEG_DIR)\n",
    "rnd.shuffle(test_files_neg)\n",
    "test_files_neg = test_files_neg[:7500]\n",
    "\n",
    "if not os.path.exists(VAL_PATH + NEG_DIR):\n",
    "    os.mkdir(VAL_PATH + NEG_DIR)\n",
    "\n",
    "for f_neg in test_files_neg:\n",
    "    shutil.move(os.path.join(TEST_PATH+NEG_DIR,f_neg), os.path.join(VAL_PATH+NEG_DIR,f_neg))\n",
    "\n",
    "test_files_pos = os.listdir(TEST_PATH+POS_DIR)\n",
    "print(\"test_files_pos len:\",len(test_files_pos))\n",
    "\n",
    "test_files_neg = os.listdir(TEST_PATH+NEG_DIR)\n",
    "print(\"test_files_neg len:\" ,len(test_files_neg))\n",
    "\n",
    "val_files_pos = os.listdir(VAL_PATH+POS_DIR)\n",
    "print(\"val_files_pos len:\" ,len(val_files_pos))\n",
    "\n",
    "val_files_neg = os.listdir(VAL_PATH+NEG_DIR)\n",
    "print(\"val_files_neg len:\" ,len(val_files_neg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275081a7",
   "metadata": {},
   "source": [
    "## 2.3  Create `tf.data.Dataset` objects\n",
    "### 2.3.1  “Small Data” Option \n",
    "Use the fact that we still have “small” data, and use pure Python code to load all the reviews into main memory and then use `from_tensor_slices` to create the `tf.data.Dataset` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fa4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_1(base_dir):\n",
    "    # Approach 1:read all reviews into a list and use from_tensor_slices.\n",
    "    # base_dir: directory name like \"./datasets/aclImdb/train\"\n",
    "    reviews = []\n",
    "    sentiments = []\n",
    "    for sentiment in[\"pos\",\"neg\"]:\n",
    "        directory = os.path.join(base_dir,sentiment)\n",
    "        for file_path in os.listdir(directory):\n",
    "            with open(os.path.join(directory,file_path),\"r\") as file:\n",
    "                reviews.append(file.readline())\n",
    "            sentiments.append(1.0 if sentiment == \"pos\" else 0.0)\n",
    "    return tf.data.Dataset.from_tensor_slices((reviews,sentiments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46aeba",
   "metadata": {},
   "source": [
    "Use the following code to print three (positive) reviews from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb8db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in create_dataset_1(\"./datasets/aclImdb/test\").take(3):\n",
    "    print(X)\n",
    "    print(y)\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4396cd",
   "metadata": {},
   "source": [
    "You may get something like (although the actual text will be different):\n",
    "```python\n",
    "tf.Tensor([b'For comedy to work, there are many factors involved:<br /><br />1.tf.Tensor(1.0, shape=(), dtype=float32)**************************************************tf.Tensor([b\"It\\'s all about getting what you want when you want it. And the\") tf.Tensor(1.0, shape=(), dtype=float32\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39def9c1",
   "metadata": {},
   "source": [
    "2.3.2  Use `TextLineDataset`\n",
    "Use `tf.data.TextLineDataset` to read the reviews directly from the files. This is a bit more complicated, but should be more scalable. You can use the following code to read the reviews from the files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_2(base_dir):\n",
    "    pos_file_paths = [os.path.join(base_dir,\"pos\", f)\n",
    "                      for f in os.listdir(os.path.join(base_dir,\"pos\"))]\n",
    "\n",
    "    neg_file_paths = [os.path.join(base_dir,\"neg\", f)\n",
    "                      for f in os.listdir(os.path.join(base_dir,\"neg\"))]\n",
    "    pos_ds = tf.data.TextLineDataset(pos_file_paths,num_parallel_reads=4).map(lambda review: (review, 1.0))\n",
    "    neg_ds = tf.data.TextLineDataset(neg_file_paths,num_parallel_reads=4).map(lambda review: (review, 0.0))\n",
    "    return pos_ds.concatenate(neg_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499cdd88",
   "metadata": {},
   "source": [
    "You will have to think of a way to:\n",
    "- Attach the labels to the reviews.\n",
    "- Combine the twotf.data.Datasets into a single `tf.data.Dataset`.\n",
    "\n",
    "The code above to print some reviews should still work if you replace `create_dataset_1` by `create_dataset_2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803374d9",
   "metadata": {},
   "source": [
    "### 2.3.3  Create the Training, Validation and Test sets\n",
    "Finally, create the actual dataset objects that will be used to train the model. \n",
    "- We need to shuffle the training data (but not the validation nor the test data). \n",
    "- All datasets need to be batched. Use a batch size of 512 (but make this easily changeable). Use prefetching on all datasets\n",
    "\n",
    "`Prefetch` zorgt voor overlap tussen data-voorbereiding en training.\n",
    "- Zonder: De computer leest data $\\rightarrow$ wacht $\\rightarrow$ traint $\\rightarrow$ wacht $\\rightarrow$ leest data. (CPU en GPU wachten op elkaar).\n",
    "- Met: Terwijl de GPU traint op Batch 1, bereidt de CPU op de achtergrond Batch 2 alvast voor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7f7b12e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "train_ds = (\n",
    "    create_dataset_2(TRAIN_PATH)\n",
    "    .shuffle(buffer_size=15_000,seed=42)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(1)\n",
    ")\n",
    "val_ds = (\n",
    "    create_dataset_2(VAL_PATH)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(1)\n",
    ")\n",
    "test_ds = (\n",
    "    create_dataset_2(TEST_PATH)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bfbb86",
   "metadata": {},
   "source": [
    "## 2.4  Create and train a Model with a Multi-Hot Encoding\n",
    "In the exercise in chapter 10, we encoded each review as a multi-hot encoded sequence, and we “hand-coded” this conversion logic. Use the `TextVectorization` layer to convert the reviews to multi-hot encoded sequences. The vocabulary should be limited to 10000 tokens.\n",
    "\n",
    "Call your layer `multi_hot_layer`. Next, create a function called `get_model` that is basically the same as the `get_model` function from the exercise in chapter 10, but takes an argument called `conversion_layer`. This argument is inserted as the first actual layer in the model (after the input layer which specifiesthe shape and the data-type of the input).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    print(\"Shape van de tekst-batch:\", text_batch.shape)\n",
    "    print(\"Shape van de label-batch:\", label_batch.shape)\n",
    "print(train_ds.counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = ks.layers.TextVectorization(\n",
    "    max_tokens=10_000,\n",
    "    output_mode=\"multi_hot\",\n",
    "    name=\"mutli_hot_layer\"\n",
    ")\n",
    "vectorize_layer.adapt(train_ds.map(lambda x, y: x))\n",
    "\n",
    "\n",
    "def get_model(conversion_layer):\n",
    "    return ks.Sequential([\n",
    "        ks.Input(shape=(), dtype=tf.string),\n",
    "        conversion_layer,\n",
    "\n",
    "        ks.layers.Dense(16, activation=\"relu\"),\n",
    "        ks.layers.Dense(16, activation=\"relu\"),\n",
    "\n",
    "        ks.layers.Dense(1,activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "\n",
    "model = get_model(vectorize_layer)\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[ks.callbacks.EarlyStopping(patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d8a586",
   "metadata": {},
   "source": [
    "Next, compile and train the model as in chapter 10. Use anEarlyStoppingcallback to prevent (too much) overfitting.Evaluate your model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f525e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d541ca",
   "metadata": {},
   "source": [
    "## 2.5  Create and train a Model with a TF-IDF Encoding\n",
    "Repeat the previous step, but now use the TextVectorization layer to convert the reviews to TF-IDF encoded sequences. Check that this second model has\n",
    "the same number of parameters as the first one, since we are still using a sparse representation of the reviews.\n",
    "\n",
    "You should find that the model with TF-IDF performs very similar to (butslightly worse than) the model with multi-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2e5a3349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 17:16:16.172110: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     49/Unknown \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.7370 - loss: 0.5981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 17:16:18.795720: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-12-29 17:16:18.795736: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9748362425322897822\n",
      "2025-12-29 17:16:18.795741: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[StatefulPartitionedCall/Cast_1/_3]]\n",
      "2025-12-29 17:16:18.795749: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 1675191259102476621\n",
      "2025-12-29 17:16:18.795752: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 16694153430287954310\n",
      "2025-12-29 17:16:18.795778: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8775966779215483281\n",
      "2025-12-29 17:16:18.795785: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 11672057714277080287\n",
      "2025-12-29 17:16:18.795789: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 754319133027944027\n",
      "2025-12-29 17:16:18.795796: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2318115664796731094\n",
      "2025-12-29 17:16:18.795801: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9707643298172041070\n",
      "2025-12-29 17:16:18.795804: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6057846784743536610\n",
      "2025-12-29 17:16:18.795807: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6938718147936098262\n",
      "2025-12-29 17:16:18.795809: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 13500205452713712504\n",
      "2025-12-29 17:16:18.795812: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9476041912592672748\n",
      "2025-12-29 17:16:18.795815: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3718795962850729306\n",
      "/Users/buraq-mac/Documents/School/CollegeFiles/DeepLearning/Deep_Learning_Exercises/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7812 - loss: 0.5075 - val_accuracy: 0.8317 - val_loss: 0.4190\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 17:16:19.696303: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-12-29 17:16:19.696322: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[StatefulPartitionedCall/Shape/_4]]\n",
      "2025-12-29 17:16:19.696329: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 14496291967522025398\n",
      "2025-12-29 17:16:19.696338: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15889671321312324402\n",
      "2025-12-29 17:16:19.696344: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2665769967199814456\n",
      "2025-12-29 17:16:19.696347: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 999896309109720813\n",
      "2025-12-29 17:16:19.696357: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8402937684174718300\n",
      "2025-12-29 17:16:19.696362: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 12031178677076522404\n",
      "2025-12-29 17:16:19.696366: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9735635423891166250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8948 - loss: 0.2902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 17:16:21.294072: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-12-29 17:16:21.294088: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[unknown_2/_15]]\n",
      "2025-12-29 17:16:21.294100: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9748362425322897822\n",
      "2025-12-29 17:16:21.294107: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 13115765615121797607\n",
      "2025-12-29 17:16:21.294110: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 16694153430287954310\n",
      "2025-12-29 17:16:21.294118: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2318115664796731094\n",
      "2025-12-29 17:16:21.294121: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6057846784743536610\n",
      "2025-12-29 17:16:21.294129: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 1675191259102476621\n",
      "2025-12-29 17:16:21.294134: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9707643298172041070\n",
      "2025-12-29 17:16:21.294137: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8775966779215483281\n",
      "2025-12-29 17:16:21.294139: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9476041912592672748\n",
      "2025-12-29 17:16:21.294143: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 11672057714277080287\n",
      "2025-12-29 17:16:21.294147: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 754319133027944027\n",
      "2025-12-29 17:16:21.294151: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 13500205452713712504\n",
      "2025-12-29 17:16:21.294154: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6938718147936098262\n",
      "2025-12-29 17:16:21.294157: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3718795962850729306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9020 - loss: 0.2723 - val_accuracy: 0.8761 - val_loss: 0.3263\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 17:16:21.975123: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-12-29 17:16:21.975135: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[StatefulPartitionedCall/sequential_13_1/mutli_hot_layer_1/StringSplit/strided_slice_1/_12]]\n",
      "2025-12-29 17:16:21.975144: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6591945317510752553\n",
      "2025-12-29 17:16:21.975146: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2665769967199814456\n",
      "2025-12-29 17:16:21.975153: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9735635423891166250\n",
      "2025-12-29 17:16:21.975157: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8402937684174718300\n",
      "2025-12-29 17:16:21.975159: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 10083350319802912053\n",
      "2025-12-29 17:16:21.975168: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 12031178677076522404\n",
      "2025-12-29 17:16:21.975176: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17801456960509093524\n",
      "2025-12-29 17:16:21.975180: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15889671321312324402\n",
      "2025-12-29 17:16:21.975184: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 14496291967522025398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9298 - loss: 0.1962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 17:16:23.563325: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-12-29 17:16:23.563338: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[unknown_3/_42]]\n",
      "2025-12-29 17:16:23.563347: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9748362425322897822\n",
      "2025-12-29 17:16:23.563351: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8775966779215483281\n",
      "2025-12-29 17:16:23.563355: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 11056978689330895335\n",
      "2025-12-29 17:16:23.563359: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 13115765615121797607\n",
      "2025-12-29 17:16:23.563362: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 11672057714277080287\n",
      "2025-12-29 17:16:23.563365: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 754319133027944027\n",
      "2025-12-29 17:16:23.563368: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 1675191259102476621\n",
      "2025-12-29 17:16:23.563425: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 16694153430287954310\n",
      "2025-12-29 17:16:23.563460: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2318115664796731094\n",
      "2025-12-29 17:16:23.563465: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6057846784743536610\n",
      "2025-12-29 17:16:23.563468: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9707643298172041070\n",
      "2025-12-29 17:16:23.563471: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9476041912592672748\n",
      "2025-12-29 17:16:23.563474: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 13500205452713712504\n",
      "2025-12-29 17:16:23.563477: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6938718147936098262\n",
      "2025-12-29 17:16:23.563480: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3718795962850729306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9268 - loss: 0.2021 - val_accuracy: 0.8764 - val_loss: 0.3247\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 17:16:24.297657: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-12-29 17:16:24.297672: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2665769967199814456\n",
      "2025-12-29 17:16:24.297677: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[StatefulPartitionedCall/sequential_13_1/mutli_hot_layer_1/StringSplit/strided_slice_1/_12]]\n",
      "2025-12-29 17:16:24.297686: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6591945317510752553\n",
      "2025-12-29 17:16:24.297691: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9735635423891166250\n",
      "2025-12-29 17:16:24.297696: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 10083350319802912053\n",
      "2025-12-29 17:16:24.297703: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8402937684174718300\n",
      "2025-12-29 17:16:24.297714: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 12031178677076522404\n",
      "2025-12-29 17:16:24.297719: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17801456960509093524\n",
      "2025-12-29 17:16:24.297723: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15889671321312324402\n",
      "2025-12-29 17:16:24.297726: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 14496291967522025398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9453 - loss: 0.1588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 17:16:25.903504: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-12-29 17:16:25.903519: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9748362425322897822\n",
      "2025-12-29 17:16:25.903523: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[StatefulPartitionedCall/sequential_13_1/mutli_hot_layer_1/SelectV2/_22]]\n",
      "2025-12-29 17:16:25.903526: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 13115765615121797607\n",
      "2025-12-29 17:16:25.903528: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8775966779215483281\n",
      "2025-12-29 17:16:25.903531: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 754319133027944027\n",
      "2025-12-29 17:16:25.903533: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 1675191259102476621\n",
      "2025-12-29 17:16:25.903536: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 11672057714277080287\n",
      "2025-12-29 17:16:25.903543: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 16694153430287954310\n",
      "2025-12-29 17:16:25.903546: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2318115664796731094\n",
      "2025-12-29 17:16:25.903548: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6057846784743536610\n",
      "2025-12-29 17:16:25.903550: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9707643298172041070\n",
      "2025-12-29 17:16:25.903553: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9476041912592672748\n",
      "2025-12-29 17:16:25.903555: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 13500205452713712504\n",
      "2025-12-29 17:16:25.903558: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6938718147936098262\n",
      "2025-12-29 17:16:25.903561: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3718795962850729306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9418 - loss: 0.1651 - val_accuracy: 0.8733 - val_loss: 0.3448\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 17:16:26.593833: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-12-29 17:16:26.593847: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2665769967199814456\n",
      "2025-12-29 17:16:26.593851: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9735635423891166250\n",
      "2025-12-29 17:16:26.593853: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[StatefulPartitionedCall/sequential_13_1/mutli_hot_layer_1/StringSplit/strided_slice_1/_12]]\n",
      "2025-12-29 17:16:26.593859: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8402937684174718300\n",
      "2025-12-29 17:16:26.593863: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6591945317510752553\n",
      "2025-12-29 17:16:26.593867: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 12031178677076522404\n",
      "2025-12-29 17:16:26.593870: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 10083350319802912053\n",
      "2025-12-29 17:16:26.593875: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17801456960509093524\n",
      "2025-12-29 17:16:26.593878: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15889671321312324402\n",
      "2025-12-29 17:16:26.593881: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 14496291967522025398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9550 - loss: 0.1310"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 17:16:28.206026: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-12-29 17:16:28.206044: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9748362425322897822\n",
      "2025-12-29 17:16:28.206047: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[StatefulPartitionedCall/sequential_13_1/mutli_hot_layer_1/SelectV2/_22]]\n",
      "2025-12-29 17:16:28.206051: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 13115765615121797607\n",
      "2025-12-29 17:16:28.206054: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8775966779215483281\n",
      "2025-12-29 17:16:28.206059: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 754319133027944027\n",
      "2025-12-29 17:16:28.206062: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 1675191259102476621\n",
      "2025-12-29 17:16:28.206066: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 11672057714277080287\n",
      "2025-12-29 17:16:28.206072: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 16694153430287954310\n",
      "2025-12-29 17:16:28.206074: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2318115664796731094\n",
      "2025-12-29 17:16:28.206077: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9707643298172041070\n",
      "2025-12-29 17:16:28.206079: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9476041912592672748\n",
      "2025-12-29 17:16:28.206083: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6057846784743536610\n",
      "2025-12-29 17:16:28.206085: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 13500205452713712504\n",
      "2025-12-29 17:16:28.206088: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6938718147936098262\n",
      "2025-12-29 17:16:28.206090: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3718795962850729306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9524 - loss: 0.1362 - val_accuracy: 0.8705 - val_loss: 0.3724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 17:16:28.928067: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-12-29 17:16:28.928086: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2665769967199814456\n",
      "2025-12-29 17:16:28.928093: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9735635423891166250\n",
      "2025-12-29 17:16:28.928096: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8402937684174718300\n",
      "2025-12-29 17:16:28.928099: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 12031178677076522404\n",
      "2025-12-29 17:16:28.928102: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17801456960509093524\n",
      "2025-12-29 17:16:28.928104: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15889671321312324402\n",
      "2025-12-29 17:16:28.928107: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 14496291967522025398\n",
      "2025-12-29 17:16:28.928110: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[StatefulPartitionedCall/sequential_13_1/mutli_hot_layer_1/StringSplit/strided_slice_1/_12]]\n",
      "2025-12-29 17:16:28.928120: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6591945317510752553\n",
      "2025-12-29 17:16:28.928125: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 10083350319802912053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x35e25f2f0>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer = ks.layers.TextVectorization(\n",
    "    max_tokens=10_000,\n",
    "    output_mode=\"tf_idf\",\n",
    "    name=\"mutli_hot_layer\",\n",
    ")\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    vectorize_layer.adapt(train_ds.map(lambda x, y: x))\n",
    "\n",
    "tf_idf_model = get_model(vectorize_layer)\n",
    "tf_idf_model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "tf_idf_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[ks.callbacks.EarlyStopping(patience=2)]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
