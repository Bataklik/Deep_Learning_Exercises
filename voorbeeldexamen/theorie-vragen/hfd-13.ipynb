{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb64730f",
   "metadata": {},
   "source": [
    "# Theorische vragen Deep Learning\n",
    "\n",
    "Sabine De Vreese, Stijn Lievens en Simon De Gheselle\n",
    "\n",
    "24 oktober 2025\n",
    "\n",
    "## Inleiding\n",
    "Hieronder vind je een vragenlijst die je kan helpen bij het studeren voor het theorie-examen van het opleidingsonderdeel Deep Learning. Veel vragen op het theorie-examen zullen gebaseerd zijn op de lijst van onderstaande vragen. Het is dus een goed idee als je minstens deze vragen kan beant-woorden op het moment dat je het examen aflegt.\n",
    "\n",
    "## Hoofdstuk 13: Inladen en Voorbehandelen van Data met Tensorflow\n",
    "1. Deze vraag gaat over “embeddings”.\n",
    "- Wat is een “embedding”?\n",
    "    > Embedding zet een token om naar een vector van getallen, waarbij positie in ruimte betekenis van het woordt geeft.\n",
    "\n",
    "- Wat zijn de hyperparameters van een “embedding” laag?\n",
    "    > Vocabulary size (woordenschat grootte), bv. [UNK, 'Tafel', 'Stoel']\\\n",
    "    > Embedding dim. (woord grootte)\\\n",
    "    > Input length (seq length), korte zinnen worden opgevuld met *padding*\n",
    "- Hoeveel trainbare parameters bevat een “embedding” laag?\n",
    "    > Elk woord krijgt een willekeurige vector. Waarbij het model meer tekst ziet, worden de getallen van de vector aangepast\n",
    "    >\n",
    "    > $\\text{Aantal parameters} = \\text{Vocabulaire grootte} \\times \\text{Embedding dimensie}$\n",
    "    >\n",
    "    > $10\\;000\\;(\\text{woorden}) * 256\\;(\\text{dimensie}) = 2\\;560\\;000\\;\\text{parameters}$\n",
    "\n",
    "2. Beschrijf in detail hoe de `shuffle` methode van `tf.data.Dataset` werkt. Wat is het effect van de parameter `buffer_size`?\n",
    "    > Shuffle schudt elementen van de dataset door middel van een buffer. Eén element komt de buffer binnen op basis van de buffer_size, en één willekeurig element wordt geretourneerd (herhaald voor elk element). Dit is efficiënt voor RAM-geheugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfe6ce17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 15:01:40.243459: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3,4,5,6,7,8,9,10])\n",
    "dataset = dataset.shuffle(buffer_size=4)\n",
    "for element in dataset:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856700ad",
   "metadata": {},
   "source": [
    "3. Deze vraag gaat over de methode [TF-IDF](https://www.youtube.com/watch?v=vZAXpvHhQow).\n",
    "- Wat betekent de afkorting TF-IDF?\n",
    "    > Term Frequency - Inverse Document Frequency\n",
    "- Wat zijn de twee factoren die de TF-IDF score bepalen van een woord in een document dat zelf behoort tot een corpus van documenten. Het is voldoende om dit op een kwalitatieve manier te beschrijven. (Je moet m.a.w. geen precieze formules kunnen geven.)\n",
    "    > Aantal keer het woord voorkomt in een document (TF) en aantal keer het woord voorkomt in de documenten van het corups.\n",
    "- Is TF-IDF een ijle (“sparse”) of een dichte (“dense”) representatie van een document?\n",
    "    > Ja **sparse**, want alles wordt op `nullen` gezet, behalve het gezochte woord niet.\n",
    "- Wat is het voordeel van het gebruik van TF-IDF vergeleken met het eenvoudig tellen van woordvoorkomens?\n",
    "    > Met TF-IDF kun je zien hoe belangrijk een woord is, ten opzichte van gewoon tellen. Woorden die veel voorkomen zoals `stopwoorden` worden genegeerd.\n",
    "\n",
    "    Voorbeeld:\n",
    "\n",
    "    Corups D\\\n",
    "        $d_1$ A quick brown *fox* jumps over the lazy dogs. What a *fox*!\\\n",
    "        $d_2$ A quick brown *fox* jumps over the lazy *fox*. What a *fox*!\n",
    "    \n",
    "    Term-frequency\n",
    "    - $TF(\"fox,d1\") = \\frac{2\\;\\text{aantal keer `fox`}}{12\\;\\text{aantal woorden in zin}} = 0.16$\\\n",
    "    - $TF(\"fox,d2\") = \\frac{3\\;\\text{aantal keer `fox`}}{12\\;\\text{aantal woorden in zin}}= 0.25$\n",
    "\n",
    "    Inverse document frequency\n",
    "    - $IDF(\"fox\",D) = \\log(\\frac{2\\;\\text{aantal documenten}}{2\\;\\text{aantal documenten woord voorkomt}}) = 0$\n",
    "    \n",
    "    TF-IDF Score\n",
    "    - $\\text{TF-IDF}(\"fox\",d_1,D) = 0.16 * 0 = 0$\n",
    "    - $\\text{TF-IDF}(\"fox\",d_2,D) = 0.25 * 0 = 0$\n",
    "\n",
    "    $\\rightarrow$ Het woordt `fox` is een algemeen woord, omdat het in elk document staat. Dit betekent dat het niet zo belangrijk is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90018e",
   "metadata": {},
   "source": [
    "4. Voor dit hoofdstuk moet je ook in staat zijn om eenvoudige vragen i.v.m.de verschillende “preprocessing” lagen in Keras te beantwoorden. Enkelevoorbeeldvragen worden hieronder gegeven.\n",
    "\n",
    "-   Wat is de uitvoer van onderstaande code?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "997b87f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- age_categories -> discretize_layer(age) ---\n",
      "tf.Tensor(\n",
      "[[0]\n",
      " [3]\n",
      " [3]\n",
      " [0]\n",
      " [2]\n",
      " [1]], shape=(6, 1), dtype=int32)\n",
      "--- onehot_layer -> onehot_layer(age_categories) ---\n",
      "tf.Tensor(\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]], shape=(6, 4), dtype=float32)\n",
      "------\n",
      "--- two_age_categories -> onehot_layer(two_age_categories) ---\n",
      "tf.Tensor(\n",
      "[[0. 1. 0. 1.]\n",
      " [1. 0. 0. 1.]\n",
      " [0. 1. 1. 0.]], shape=(3, 4), dtype=float32)\n",
      "--- onehot_layer -> onehot_layer(two_age_categories) ---\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 0.]], shape=(3, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import keras as ks\n",
    "\n",
    "age = ks.ops.convert_to_tensor([\n",
    "    [10.], [88.], [77.], [16.], [45.], [25.]\n",
    "])\n",
    "discretize_layer = ks.layers.Discretization(bin_boundaries=[18., 35., 65.])\n",
    "# * 0 < 18 = [10,16] -> Bin 0\n",
    "# * 18 <= x 35 = [25] -> Bin 1\n",
    "# * 35 <= X < 65 = [45] -> Bin 2\n",
    "# * x >= 65 = [77, 88] -> Bin 3\n",
    "age_categories = discretize_layer(age)\n",
    "print(\"--- age_categories -> discretize_layer(age) ---\")\n",
    "print(age_categories)\n",
    "# * [[0], [3], [3], [0], [2], [1]]\n",
    "\n",
    "onehot_layer = ks.layers.CategoryEncoding(num_tokens=4)\n",
    "print(\"--- onehot_layer -> onehot_layer(age_categories) ---\")\n",
    "print(onehot_layer(age_categories))\n",
    "#* [[1,0,0,0], [0,0,0,1], [0,0,0,1], [1,0,0,0],[0,0,1,0], [0,1,0,0]]\n",
    "\n",
    "print(\"------\")\n",
    "two_age_categories = ks.ops.convert_to_tensor([[3, 1], [3, 0], [2, 1]])\n",
    "print(\"--- two_age_categories -> onehot_layer(two_age_categories) ---\")\n",
    "print(onehot_layer(two_age_categories))\n",
    "#* [[0,1,0,1], [1,0,0,1],[0,1,1,0]]\n",
    "\n",
    "onehot_layer = ks.layers.CategoryEncoding(num_tokens=4 + 4)\n",
    "print(\"--- onehot_layer -> onehot_layer(two_age_categories) ---\")\n",
    "print(onehot_layer(two_age_categories + [0, 4])) #* [[3, 5], [3, 4], [2, 5]]\n",
    "#* [[0,0,0,1,0,1,0,0], [0,0,0,1,1,0,0,0], [0,0,1,0,0,1,0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a92bb",
   "metadata": {},
   "source": [
    "-   De onderstaande code:\n",
    "    Uitvoer\n",
    "    ```python\n",
    "    tf.Tensor(\n",
    "        [[2]\n",
    "        [4]\n",
    "        [3]\n",
    "        [0]], shape=(4, 1), dtype=int64)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b759791e",
   "metadata": {},
   "source": [
    "`StringLookUp` zoekt worden in een lijst.\n",
    "- index 0 $\\rightarrow$ Out-Of-Vocabulary (OOV) / UNK, niet in de lijst stond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f12f190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2]\n",
      " [4]\n",
      " [3]\n",
      " [0]\n",
      " [1]], shape=(5, 1), dtype=int64)\n",
      "['[UNK]', 'Gent', 'Kortrijk', 'Brussel', 'Aalst']\n"
     ]
    }
   ],
   "source": [
    "cities = [\"Brussel\",\"Aalst\",\"Gent\",\"Kortrijk\",\"Gent\"]\n",
    "str_lookup_layer = ks.layers.StringLookup()\n",
    "str_lookup_layer.adapt(cities)\n",
    "print(str_lookup_layer([[\"Kortrijk\"], [\"Aalst\"], [\"Brussel\"], [\"Brugge\"],[\"Gent\"]]))\n",
    "print(str_lookup_layer.get_vocabulary())\n",
    "#* ['[UNK]', 'Gent', 'Kortrijk', 'Brussel', 'Aalst']\n",
    "#* Kortrijk -> 2\n",
    "#* Aalst -> 4\n",
    "#* Brussel -> 3\n",
    "#* Brugge -> OOV / [UNK] -> 0\n",
    "#* Gent -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa8ba36",
   "metadata": {},
   "source": [
    "Verklaar.\n",
    "> #* ['[UNK]', 'Gent', 'Kortrijk', 'Brussel', 'Aalst']\\\n",
    "> \n",
    "> #* Kortrijk -> 2\\\n",
    "> #* Aalst -> 4\\\n",
    "> #* Brussel -> 3\\\n",
    "> #* Brugge -> `OOV` / `'[UNK]'` -> 0\\\n",
    "> #* Gent -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf2a3f",
   "metadata": {},
   "source": [
    "Gegeven de resultaten van bovenstaande code, wat is de uitvoer vanonderstaande code?\n",
    "> - Elk waarde + '[UNK]' wordt gesorteerd van groot naar klein met `[UNK]` als eerste waarde. Daarna worden de positie van het woord in een array aangeduid met 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47692698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0 0 1]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 1]], shape=(4, 5), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "cities = [\"Brussel\",\"Aalst\",\"Gent\",\"Kortrijk\",\"Gent\"]\n",
    "str_lookup_layer = ks.layers.StringLookup(output_mode=\"one_hot\")\n",
    "str_lookup_layer.adapt(cities)\n",
    "#* ['[UNK]', 'Gent', 'Kortrijk', 'Brussel', 'Aalst']\n",
    "#* [[0 0 0 0 1], [0,0,1,0,0], [0,1,0,0,0], [0,0,0,0,1]]\n",
    "print(str_lookup_layer([[\"Aalst\"], [\"Kortrijk\"], [\"Gent\"], [\"Aalst\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c8036",
   "metadata": {},
   "source": [
    "De onderstaande code, geeft als uitvoer\n",
    "```python\n",
    "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=array([[5],[1],[1],[6],[7]])>\n",
    "```\n",
    "Verklaar\n",
    "- `num_oov_indices=5` voegt 5 `[UNK]` voor aan de vocabulary lijst, daarom zijn de indices anders.\n",
    "\n",
    "    `['[UNK]','[UNK]','[UNK]','[UNK]','[UNK]', 'Gent', 'Kortrijk', 'Brussel', 'Aalst']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aac2049b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'Gent', 'Kortrijk', 'Brussel', 'Aalst']\n",
      "tf.Tensor(\n",
      "[[5]\n",
      " [1]\n",
      " [1]\n",
      " [6]\n",
      " [7]], shape=(5, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "str_lookup_layer = ks.layers.StringLookup(num_oov_indices=5)\n",
    "str_lookup_layer.adapt(cities)\n",
    "print(str_lookup_layer.get_vocabulary())\n",
    "#* ['[UNK]','[UNK]','[UNK]','[UNK]','[UNK]', 'Gent', 'Kortrijk', 'Brussel', 'Aalst']\n",
    "#* [5], [1], [1], [6], [7]\n",
    "print(str_lookup_layer([[\"Gent\"], [\"Hasselt\"], [\"Brugge\"], [\"Kortrijk\"], [\"Brussel\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e61cb",
   "metadata": {},
   "source": [
    "De volgende code\n",
    "geeft als uitvoer\n",
    "```python\n",
    "tf.Tensor(\n",
    "    [[6 3 5 0 0]\n",
    "    [1 7 3 5 4]], shape=(2, 5), dtype=int64)\n",
    "```\n",
    "- `TextVectorization` indices:\n",
    "  - 0 -> '' -> padding\n",
    "  - 1 -> '[UNK]' -> OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c0b7bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'amai', 'weet', 'niet', 'dat', 'je', 'ik']\n",
      "tf.Tensor(\n",
      "[[6 3 5 0 0]\n",
      " [1 7 3 5 4]], shape=(2, 5), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "train_data = [\"Amai dat weet ik niet\",\n",
    "              \"Amai, amai, amai.\",\n",
    "              \"Dat weet je niet\",\n",
    "              \"Weet je dat niet? Amai\"]\n",
    "text_vec_layer = ks.layers.TextVectorization()\n",
    "text_vec_layer.adapt(train_data)\n",
    "print(text_vec_layer.get_vocabulary())\n",
    "#* ['', '[UNK]', 'amai', 'weet', 'niet', 'dat', 'je', 'ik']\n",
    "#* [6 3 5 0 0]\n",
    "#* [1 7 3 5 4]\n",
    "print(text_vec_layer([\"Je weet dat\",\"Tja, ik weet dat niet\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eeedd5",
   "metadata": {},
   "source": [
    "Wat is de uitvoer van de onderstaande code?\n",
    "\n",
    "```python\n",
    "print(text_vec_layer(\n",
    "    [\"Weet zij dat? Amai\",\n",
    "    \"Neen, ik wist dat\"]\n",
    "    ))\n",
    "```\n",
    "> $[[3 1 5 2]$\\\n",
    "> $[1 7 1 5]]$\\\n",
    "> shape(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca9a37e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 1 5 2]\n",
      " [1 7 1 5]], shape=(2, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(text_vec_layer(\n",
    "    [\"Weet zij dat? Amai\",\n",
    "    \"Neen, ik wist dat\"]\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
