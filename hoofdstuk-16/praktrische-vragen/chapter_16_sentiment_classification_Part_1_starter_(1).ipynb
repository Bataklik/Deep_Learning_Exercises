{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Text Classification using an Encoder-Only Transformer"
      ],
      "metadata": {
        "id": "ZZLgogzsXTk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise we will build an encoder-only transformer and apply it on a text\n",
        "classification task. To better understand the model architecture, we will build and train the model (almost) from scratch.  \n",
        "\n",
        "**Note**: in practice, you would use a pretrained language model and possibly finetune it"
      ],
      "metadata": {
        "id": "2PD1vZlqP0aN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QMu0xYuRDSB"
      },
      "outputs": [],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1"
      ],
      "metadata": {
        "id": "2wWygoMoaNIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1 Copy and Change Classes from Previous Exercise**\n",
        "\n",
        "An encoder-only transformer is very similar to a decoder-only transformer:\n",
        "*   It also starts with a positional embedding.  \n",
        "We are going to use the code for ```PositionalEmbedding``` from the previous exercise.\n",
        "*   The encoder blocks employ the same ```FeedForward``` layer as the decoder blocks.  \n",
        "We are going to use the code for ```FeedForward``` from the previous exercise.\n",
        "*   The encoder block itself is very similar to the decoder block in a decoder-only transformer.  \n",
        "We are going to use the code for ```GTPDecoderBlock``` from the previous exercise.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ixXLKowYQDrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@keras.saving.register_keras_serializable()\n",
        "class FeedForward(keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, factor=4, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.factor = factor\n",
        "    self.relu = keras.activations.relu\n",
        "\n",
        "  def build(self, batch_input_shape):\n",
        "    time_steps, embed_size = batch_input_shape[1:]\n",
        "    self.kernel1 = self.add_weight(shape=(embed_size, self.factor*embed_size))\n",
        "    self.bias1 = self.add_weight(shape=(self.factor*embed_size, ),\n",
        "                                 initializer=\"zeros\")\n",
        "    self.kernel2 = self.add_weight(shape=(self.factor*embed_size, embed_size))\n",
        "    self.bias2 = self.add_weight(shape=(embed_size, ),\n",
        "                                 initializer=\"zeros\")\n",
        "\n",
        "  def call(self, inputs):\n",
        "    a =  self.relu(keras.ops.matmul(inputs, self.kernel1) + self.bias1)\n",
        "    return keras.ops.matmul(a, self.kernel2) + self.bias2\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super().get_config()\n",
        "    return {\n",
        "        **base_config,\n",
        "        \"factor\": self.factor,\n",
        "    }\n",
        "\n",
        "# Embedding with Position\n",
        "@keras.saving.register_keras_serializable()\n",
        "class EmbeddingWithPosition(keras.layers.Layer):\n",
        "  \"\"\"\n",
        "  Computes and embedding and also adds a positional embedding.\n",
        "  This layer does not support masking.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_tokens, max_seq_length, embed_size, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.num_tokens = num_tokens\n",
        "    self.max_seq_length = max_seq_length\n",
        "    self.embed_size = embed_size\n",
        "\n",
        "  def build(self, batch_input_shape):\n",
        "    # Shape not needed\n",
        "    # print(f\"Build called with {batch_input_shape} as shape\")\n",
        "\n",
        "    self.kernel = self.add_weight(shape=(self.num_tokens, self.embed_size))\n",
        "    self.pos_kernel = self.add_weight(shape=(self.max_seq_length, self.embed_size))\n",
        "\n",
        "  def call(self, inputs):\n",
        "    _, length = keras.ops.shape(inputs)\n",
        "\n",
        "    embeddings = keras.ops.take(self.kernel, inputs, axis=0) # (batch, length, embed_size)\n",
        "    pos_embeddings = self.pos_kernel[:length]\n",
        "\n",
        "    return embeddings + pos_embeddings # rely on broadcasting. Mask is lost\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super().get_config()\n",
        "    return {\n",
        "        **base_config,\n",
        "        \"num_tokens\": self.num_tokens,\n",
        "        \"max_seq_length\": self.max_seq_length,\n",
        "        \"embed_size\": self.embed_size\n",
        "    }"
      ],
      "metadata": {
        "id": "BaGLk-rkRJTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the following changes to ```GPTDecoderBlock```:\n",
        "*   Rename the class to ```EncoderBlock```.\n",
        "*   The multi-headed attention does not need the causal mask when it is called, since each token is allowed to attend to all tokens before Ã¡nd after it. Remove the causal mask."
      ],
      "metadata": {
        "id": "9vMGJSrhSTQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A GPT decoder block (without cross attention)\n",
        "@keras.saving.register_keras_serializable()\n",
        "class GPTDecoderBlock(keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, num_heads, embed_size, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.num_heads = num_heads\n",
        "    self.embed_size = embed_size\n",
        "\n",
        "    self.masked_multi_head_attn = keras.layers.MultiHeadAttention(\n",
        "        num_heads=self.num_heads,\n",
        "        key_dim = self.embed_size // self.num_heads\n",
        "    )\n",
        "    self.layer_norm_1 = keras.layers.LayerNormalization()\n",
        "    self.feed_forward = FeedForward()\n",
        "    self.layer_norm_2 = keras.layers.LayerNormalization()\n",
        "\n",
        "  def build(self):\n",
        "    pass\n",
        "\n",
        "  def call(self, inputs):\n",
        "    skip = inputs\n",
        "    inputs = self.masked_multi_head_attn(inputs, inputs, use_causal_mask=True)\n",
        "    inputs = self.layer_norm_1(keras.layers.Add()([inputs, skip]))\n",
        "\n",
        "    skip = inputs\n",
        "    inputs = self.feed_forward(inputs)\n",
        "    inputs = self.layer_norm_2(keras.layers.Add()([skip, inputs]))\n",
        "    return inputs\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super().get_config()\n",
        "    return {\n",
        "        **base_config,\n",
        "        \"num_heads\": self.num_heads,\n",
        "        \"embed_size\": self.embed_size\n",
        "    }"
      ],
      "metadata": {
        "id": "lVpwP5HBRXKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 Create an Encoder-Only Classification Model**  \n",
        "The encoder from the original \"Attention is all you Need\" paper outputs contextual\n",
        "embeddings of shape: (```batch_size```, ```seq_length```, ```embed_size```).  \n",
        "**Note**: in principle this model will work with any sequence length, as\n",
        "long as it is not longer than the maximum sequence length as specified in ```PositionalEmbedding```.\n",
        "We need a way of attaching a small network for classification on top of these contextual embeddings. We will do the following (other options are certainly possible):\n",
        "\n",
        "*  First, we will reduce the contextual embeddings of shape\n",
        "(```batch_size```, ```seq_length```, ```embed_size```) to a tensor of fixed size by\n",
        "viewing these contextual embeddings as a one-dimensional sequence and applying a one-dimensional global average pooling layer to it. This reduces the\n",
        "contextual embeddings to a tensor of size (```batch_size```, ```embed_size```).\n",
        "*  Next, we add a fully connected layer with ```embed_size``` units and the ReLU\n",
        "activation function.\n",
        "*  Finally, we add a fully connected layer with the correct number of units and\n",
        "the correct activation function given the type of classification problem."
      ],
      "metadata": {
        "id": "F6S9UG-RTmvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_classification_encoder_model(\n",
        "    num_tokens: int, max_seq_length: int,\n",
        "    embed_size: int, num_heads:int, num_blocks:int,\n",
        "    num_classes:int,\n",
        "    use_mask=False,\n",
        "    scale_embeddings=False):\n",
        "  \"\"\"\n",
        "  num_tokens: the vocabulary size\n",
        "  max_seq_length: maximum length of any sequence\n",
        "  embed_size: the embedding dimension\n",
        "  num_heads: the number of heads in each multi-headed attention\n",
        "  num_blocks: the number of encoder blocks\n",
        "  num_classes: the number of classes to classify the text into\n",
        "  \"\"\"\n",
        "  inputs = keras.layers.Input(shape=[max_seq_length], dtype=int) # (B, LEN)\n",
        "\n",
        "  # Positional Embeddings\n",
        "  # YOUR CODE HERE\n",
        "\n",
        "  # Encoder blocks\n",
        "  # YOUR CODE HERE\n",
        "\n",
        "  # Simplest classification head\n",
        "  # Classification network on top of contextual embeddings\n",
        "  # YOUR CODE HERE\n",
        "\n",
        "  return keras.Model(inputs=inputs, outputs=output)"
      ],
      "metadata": {
        "id": "A8CN57bIRotx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data\n",
        "\n",
        "**2.3 Apply the Model to the IMDB-Dataset**  \n",
        "We will now apply this model to the built-in IMDB-dataset. Load the data:"
      ],
      "metadata": {
        "id": "clCSau2JSBYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN=500\n",
        "NUM_TOKENS=10_000"
      ],
      "metadata": {
        "id": "IIJt0p_GSDKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data(num_words=NUM_TOKENS)"
      ],
      "metadata": {
        "id": "zqMT6LFBSJkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not all reviews contain the same number of words. Use a method from\n",
        "```keras.utils``` to pad the reviews so that they all have the same length. Use arguments so that\n",
        "*  padding tokens are added at the end of reviews that are shorter than ```MAX_LEN```.\n",
        "*  reviews that are longer than ```MAX_LEN``` should be truncated so that the start of the review is kept."
      ],
      "metadata": {
        "id": "ecpdg4UIUtyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pad sequences\n",
        "X_train = keras.utils....\n",
        "X_test = keras.utils...."
      ],
      "metadata": {
        "id": "OdXkoX5CSN3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set aside the first 10 000 examples of the test data as the validation set:"
      ],
      "metadata": {
        "id": "hxkHDePzVBo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = ....\n",
        "y_val = ....\n",
        "X_test = ....\n",
        "y_test = ...."
      ],
      "metadata": {
        "id": "0Sa3UwtzSSm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the data is ready, we can build a model. Use the following parameters:"
      ],
      "metadata": {
        "id": "pTtZo-ChVJPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_HEADS=4\n",
        "EMBED_SIZE=32\n",
        "NUM_BLOCKS=2"
      ],
      "metadata": {
        "id": "Aj8oJUM9ST9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_classification_encoder_model(\n",
        "    num_tokens=NUM_TOKENS,\n",
        "    max_seq_length=MAX_LEN,\n",
        "    embed_size=EMBED_SIZE,\n",
        "    num_heads=NUM_HEADS,\n",
        "    num_blocks=NUM_BLOCKS,\n",
        "    num_classes=1)"
      ],
      "metadata": {
        "id": "1NtsgUK4Sd7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many parameters does the model have? You should find that this model has 362 497 parameters, most of which are in the embedding layer.\n"
      ],
      "metadata": {
        "id": "namv3gC8VPz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "BNER_qHrSiD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and fit the model:\n",
        "*  Use the ```Adam``` optimizer with all the default values.\n",
        "*  Use early stopping to (try to) prevent (severe) overfitting. Monitor the validation accuracy, using a ```patience``` of 4. Restore the best weights.  \n",
        "\n",
        "When you train the model, you should find that it reaches a validation accuracy of around 86%, while the accuracy on the training data is much higher, so the model is definitely overfitting."
      ],
      "metadata": {
        "id": "h6bKn_5jVa_9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2Chzj6TSwwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2T-oY-pAVnF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jgBWk7_qS4RV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}