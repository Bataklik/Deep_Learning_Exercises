{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09654a52",
   "metadata": {},
   "source": [
    "1  Generating (Shakespearean) Text with a GPT-like Transformer\n",
    "\n",
    "In this exercise we are going to build a GPT-like transformer. Such a transformeris a decoder-only transformer and hence the doesn‚Äôt include a cross attentionlayer.\n",
    "\n",
    "As a practical application of the transformer, we will train it to generate Shake-spearean text.\n",
    "\n",
    "**Note**: the following video1from Andrej Karpathy explains in detail how to builda GPT-like decoder. In the video the Pytorch framework is used, but the con-cepts are identical. The video also follows the ‚ÄúAttention is all you need‚Äù paper,apart from the placement of the *LayerNormalization* layers.\n",
    "\n",
    "The overall architecture of a **decoder-only transformer** is shown in Figure 1\n",
    "\n",
    "1.1  Implement theFeedForwardLayer\n",
    "\n",
    "We start by implementing theFeedForwardlayer. According to equation (2) ofthe ‚ÄúAttention is all you Need‚Äù paper, this layer performs the following calculation:\n",
    "$$\n",
    "\\text{FFN}(ùë•) = \\text{max}(0, xW1+ b1)W_2+ b_2\n",
    "$$\n",
    "which is applied to each position (i.e. each time step) $ùë•$ independently. The dimensions of the input and output are identical, but the layer in between is 4 times wider.\n",
    "\n",
    "For this exercise, we are going to implement this layer as a subclass ofkeras.layers.Layerbut we will **not** use any other layers, instead you should [https://www.youtube.com/watch?v=kCc8FmEb1nY2](https://www.youtube.com/watch?v=kCc8FmEb1nY2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36eea0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip --quiet\n",
    "%pip install keras --quiet\n",
    "%pip install tensorflow-metal --quiet\n",
    "%pip install tensorflow-macos --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1f8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SimpleFeedForwardlayer\n",
    "import keras\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "\n",
    "class FeedForward(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, factor=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.factor = factor\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        time_steps, embed_size = batch_input_shape[1:]\n",
    "        #! YOUR CODE HERE:\n",
    "        self.w1 = self.add_weight(shape=(embed_size,self.factor*embed_size))\n",
    "        self.w2 = self.add_weight(shape=(self.factor*embed_size,embed_size))\n",
    "        self.b1 = self.add_weight(shape=(self.factor*embed_size))\n",
    "        self.b2 = self.add_weight(shape=(embed_size,))\n",
    "\n",
    "    #? Call kun je oproepen met `FeedForward()()`\n",
    "    def __call__(self, inputs):\n",
    "        #! YOUR CODE HERE:\n",
    "        #! Perform calculation on inputs and return result\n",
    "        inputs = keras.ops.matmul(inputs,self.w1)\n",
    "        inputs = keras.layers.Add()([inputs,self.b1])\n",
    "        inputs = keras.layers.Activation(\"relu\")(inputs)\n",
    "\n",
    "        inputs = keras.ops.matmul(inputs,self.w2)\n",
    "        inputs = inputs + self.b2\n",
    "        return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config,\"factor\": self.factor,}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727c876",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1f5932",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#SimpletestcodeTEST_SHAPE = (2, 10, 32)#Batchsize2,10timesteps,embeddingdimension32X = keras.random.normal(shape=TEST_SHAPE)ff = FeedForward()print(f\"Shapeofoutput{ff(X).shape}\")#Shouldprint(2,10,32)forwinff.get_weights():#Checkthattheshapesarewhatyouexpectprint(w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169354e",
   "metadata": {},
   "source": [
    "1.2  Implement a GPT Decoder Block\n",
    "\n",
    "Next, implement a *GPTDecoderBlock* class as a subclass of *keras.layers.Layer*. This layer represents one decoder block. It consists of\n",
    "- Masked (or causal) multi-head attention.\n",
    "- Layer normalization (and a skip connection)\n",
    "- A feed forward layer (which was implemented in the previous step)\n",
    "- A second layer normalization step (and a skip connection)\n",
    "\n",
    "You can see the starter code for *GPTDecoderBlock* class in Figure 3.\n",
    "\n",
    "Note the following:\n",
    "1. Keras provides a *MultiHeadAttention* attention class that you can use.In the ‚ÄúAttention is all you Need‚Äù paper it is mentioned at the end of sec-tion 3.2.2 that the dimensions for the keys and values are\n",
    "   $$\n",
    "   d_k = d_v = d_{model}/h,\n",
    "   $$\n",
    "   where $h$ denotes the number of heads and $ùëë_{model}$ is the dimension of the embeddings.\n",
    "2. In thecallmethod you need to make sure to apply the causal masking.\n",
    "3. In section 3.1 of the ‚ÄúAttention is all you Need‚Äù paper you can see thatthe skip connection and the layer normalisation are implemented as fol-lows:LayerNorm(ùë• +Sublayer(ùë•)),2If you don‚Äôt, the model will seem to learn very quickly but at test time it will not doanything useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c4231",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# A GPT decoderblock (with out crossattention)\n",
    "@keras.saving.register_keras_serializable()\n",
    "class GPTDecoderBlock(keras.layers.Layer):\n",
    "    def __init__(self, num_heads, embed_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_size = embed_size\n",
    "        #! YOUR CODE HERE\n",
    "        #! Add needed layers (either from Keras or your own custom layer)\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                                         key_dim=(embed_size//num_heads))\n",
    "        self.normalization_1 = keras.layers.LayerNormalization()\n",
    "        self.normalization_2 = keras.layers.LayerNormalization()\n",
    "        self.feed_forward_network = FeedForward()\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        #! YOUR CODE HERE\n",
    "        #! Perform the computation on inputs and return result\n",
    "        skip_connection_1 = inputs # (seq_length, embed_size)\n",
    "\n",
    "        #* Output van attention\n",
    "        x = self.attention(inputs,inputs,use_causal_mask=True)\n",
    "        #* Output van attention en normalisatie\n",
    "        x = self.normalization_1(x + skip_connection_1)\n",
    "\n",
    "        skip_connection_2 = x\n",
    "        #* Output van feedforward netwerk\n",
    "        x = self.feed_forward_network(x)\n",
    "        #* Output van feedforward en normalisatie\n",
    "        x = self.normalization_2(x + skip_connection_2)\n",
    "        return x # (seq_length, embed_size)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"num_heads\": self.num_heads, \"embed_size\": self.embed_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd247827",
   "metadata": {},
   "source": [
    "where Sublayer is either the multi-head attention layer or the feed forwardlayer.\n",
    "\n",
    "Run the following code to perform a simple test of your class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b220c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Simple test code\n",
    "TEST_SHAPE = (2, 10, 32) # Batchsize 2,10 time steps,embedding dimension 32\n",
    "\n",
    "#? Wat is mijn context window (aka length)? 10\n",
    "X = keras.random.normal(shape=TEST_SHAPE)\n",
    "gpt_block = GPTDecoderBlock(num_heads=4, embed_size=32)\n",
    "print(f\"Shape of output {gpt_block(X).shape}\") # Should print (2,10,32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec8d3ae",
   "metadata": {},
   "source": [
    "1.3  Implement a EmbeddingWithPositionLayer\n",
    "\n",
    "The decoder starts with an embedding layer which embeds the (integer) tokensinto a vector space. Next, a positional embedding is added to the token em-beddings. In the ‚ÄúAttention is all you Need‚Äù paper it is mentioned that theseembeddings can either be ‚Äúfixed‚Äù, or they can be learned.We will implement a classEmbeddingWithPositionwhich combines the tokenembedding with a learnable positional embedding. We willnotmake use of theEmbeddinglayer to implement the class. Implementing this ‚Äúby hand‚Äù will helpyou gain a better understanding of what embeddings are actually doing.Start from the code in Figure4to implement this class.Hints:1.In thebuildmethod you should add two learnable weights matrices. Thedimensions of these matrices depend on the values of the arguments thatwere passed to the constructor:‚Ä¢num_tokens: the number of tokens in the vocabulary\n",
    "max_seq_length: the maximum length of any sequence. The modelwill not work if sequences with a length longer than this maximumlength are used.‚Ä¢embed_size: the dimension of the embeddings.2.In thecallmethod, you can usekeras.ops.taketo select rows fromthe embedding matrix.3.The positional embeddings are (by definition) the firstlengthrows fromthe positional embedding matrix.4.Rely on the+operator to perform the broadcasting between the tokenembeddings and the positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab3fb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from keras.layers import EmbeddingWithPosition\n",
    "\n",
    "tokens = keras.ops.convert_to_tensor([[1,3,5],[0,2,4]])\n",
    "embed_layer = EmbeddingWithPosition(num_tokens=10, max_seq_length=5, embed_size=32)\n",
    "print(embed_layer(tokens).shape) # Should print (2,3,32)\n",
    "for w in embed_layer.get_weights(): # Check that this is what you would expect\n",
    "    print(w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7478c1",
   "metadata": {},
   "source": [
    "1.4  Build the Complete Model\n",
    "\n",
    "Write a methodget_modelthat returns a complete GPT-like decoder. Since wehave all the necessary layers, this is now a simple sequential model. Completethe code in Figure5.As you can see in Figure1, there is a linear layer after the last decoder block.This linear layer works independently for each token. For this exercise we willoutput the logits for the tokens instead of the token probabilities. Stated other-wise, the last layer in our model does not include an activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1790b0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class EmbeddingWithPosition(keras.layers.Layer):\n",
    "    def __init__(self, num_tokens, max_seq_length, embed_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        #! YOUR CODE HERE\n",
    "        #! Save constructor arguments\n",
    "        self.num_tokens = num_tokens\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.embed_size = embed_size\n",
    "    def build(self, batch_input_shape):\n",
    "        #! Shape not actually needed!!\n",
    "        #! YOUR CODE HERE\n",
    "        #! Add the weights for the two embeddings\n",
    "        #? Token kunnen omzetten naar een embedding?\n",
    "        #? token 0 (the)\n",
    "        #? --> embedding [30,45,29,..., 223,45] # 512\n",
    "        #? token 2 (or)\n",
    "        #? --> embedding [12,34,56,...,78] # 512\n",
    "        #? [\n",
    "        #? (0): [30,45,29,...,223,45],\n",
    "        #? ...\n",
    "        #? (2): [12,34,56,...,78]\n",
    "        #? ]\n",
    "        self.embedding_loop_table = self.add_weight(shape=(self.num_tokens,self.embed_size))\n",
    "        self.position_lookup_table = self.add_weight(shape=(self.max_seq_length,self.embed_size))\n",
    "    def __call__(self, inputs):\n",
    "        _, length = keras.ops.shape(inputs)\n",
    "        # YOUR CODE HERE\n",
    "        # Get both embeddings and add them.\n",
    "        token_embeddings = keras.ops.take(self.embedding_loop_table,inputs,axis=0)\n",
    "        position_embeddings = self.position_lookup_table[:length]\n",
    "        return token_embeddings + position_embeddings\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config,\"num_tokens\": self.num_tokens,\n",
    "                \"max_seq_length\": self.max_seq_length,\n",
    "                \"embed_size\": self.embed_size}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
