{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda0a372",
   "metadata": {},
   "source": [
    "# 1  Classifying the CIFAR10 Dataset\n",
    "In this exercise we are going to classify images belonging to 10 different classes,namely airplanes, automobiles, birds, cats, deer, dogs, frogs, horses, ships andtrucks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0b6cb",
   "metadata": {},
   "source": [
    "## 1 .Start by loading the dataset. \n",
    "This is a built-in dataset in keras, see https://keras.io/api/datasets/cifar10/#load_data-functionfor detailed information. Use the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c672279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab509f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = \\\n",
    "    keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac4e231",
   "metadata": {},
   "source": [
    "2. Write code to check shape of the training and the test set. Interpret thisshape, i.e. understand what each number means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df30aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_full.shape)\n",
    "print(y_train_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d149f9",
   "metadata": {},
   "source": [
    "3. Use the last 10000 examples from the training set as the validation set.The other examples will be used as training set. Write code to create thevalidation and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d09eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#? Validatie set: model wordt tussentijds geëvalueerd\n",
    "#? om te kijken of het niet overfit op de training set.\n",
    "x_val = X_train_full[-10_000:]\n",
    "y_val = y_train_full[-10_000:]\n",
    "\n",
    "#* Hier halen we de validatie set uit de train sets\n",
    "x_train = X_train_full[:-10_000]\n",
    "y_train = y_train_full[:-10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcffdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5205232",
   "metadata": {},
   "source": [
    "## 1.3  Build a Model\n",
    "\n",
    "Build a model using the Sequential API. Write a function get_model() that returns a model with the following architecture:\n",
    "• An Input object that specifies the shape of each image.\n",
    "• A Rescaling layer which scales the inputs (that are currently between 0 and 255) to the range [0, 1].\n",
    "- A Conv2 layer with 32 filters, kernel size equal to (3, 3), padding=same and the relu activation function.\n",
    "- A Conv2 layer with 32 filters, kernel size equal to (3, 3), padding=same and the relu activation function.\n",
    "- A max pooling layer with pool size equal to (2, 2).\n",
    "- A Conv2D layer with 64 filters, kernel size equal to (3, 3), padding=same and the relu activation function.\n",
    "- A Conv2 layer with 64 filters, kernel size equal to (3, 3), padding=same and the relu activation function.\n",
    "- A max pooling layer with pool size equal to (2, 2).\n",
    "- A Flatten layer that transforms each example to a long one dimensional tensor.\n",
    "- A Dense layer with 128 units and the relu activation function.\n",
    "- A Dense output layer.\n",
    "  - How many units should this layer have?\n",
    "  - What is the most appropriate activation function for this layer, given that we are doing classification into 10 classes?\n",
    "\n",
    "Create an instance of the model and verify that it has 591274 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a3ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(32,32,3)))\n",
    "    model.add(keras.layers.Rescaling(scale=1./255))\n",
    "    \"\"\"\n",
    "    A Conv2Dlayer with 32 filters,\n",
    "    kernel size equal to(3, 3),\n",
    "    padding=same and the relu activation function.\n",
    "    \"\"\"\n",
    "    model.add(keras.layers.Conv2D(filters=32,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=\"same\",\n",
    "                                  activation=\"relu\")) #* 3 of (3,3) zie docs.\n",
    "    model.add(keras.layers.Conv2D(filters=32,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=\"same\",\n",
    "                                  activation=\"relu\"))\n",
    "    \"\"\"\n",
    "    A max pooling layer with pool size equal to (2, 2).\n",
    "    \"\"\"\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2))) #* (2,2) mag weg door default, zie docs\n",
    "    \"\"\"\n",
    "    A Con2Dlayer with 64 filters,\n",
    "    kernel size equal to (3, 3),\n",
    "    padding=same and the relu activation function\n",
    "    \"\"\"\n",
    "    model.add(keras.layers.Conv2D(filters=64,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=\"same\",\n",
    "                                  activation=\"relu\"))\n",
    "    model.add(keras.layers.Conv2D(filters=64,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=\"same\",\n",
    "                                  activation=\"relu\"))\n",
    "    \"\"\"\n",
    "    A max pooling layer with pool size equal to (2, 2).\n",
    "    \"\"\"\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    \"\"\"\n",
    "    A Flatten layer that transforms each example\n",
    "    to a long one dimensional tensor\n",
    "    \"\"\"\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \"\"\"\n",
    "    A Dense layer with 128 units and\n",
    "    the relu activation function.\n",
    "    \"\"\"\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    \"\"\"\n",
    "    A Dense output layer\n",
    "    \"\"\"\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964769d8",
   "metadata": {},
   "source": [
    "## 1.4  Compile the Model\n",
    "1. Compile the model.\n",
    "    * Use the Adam the optimizer with a learning rate of 1/1000.\n",
    "    * Specify the correct loss function for this classification problem and track the percentage of correctly classified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2db42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = keras.optimizers.Adam(learning_rate=1/1000)\n",
    "#? Hoe weten welke dat we gebruiken van de loss function?\n",
    "#* Omdat we te maken hebben met een multi-class classificatie probleem\n",
    "#* en de labels zijn integers (geen one-hot encoding)\n",
    "#* gebruiken we sparse_categorical_crossentropy\n",
    "model.compile(optimizer=adam_optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b9aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping()\n",
    "\n",
    "history = model.fit(x=x_train,\n",
    "                    y=y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=100,\n",
    "                    callbacks=[early_stopping_cb],\n",
    "                    batch_size=64\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3abfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_learning_curves(history):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    for key, style in zip(history.history, [\"r-o\",\"r-*\",\"b-o\",\"b-*\"]):\n",
    "        epochs = np.array(history.epoch)\n",
    "        plt.plot(epochs + 1, history.history[key], style, label=key)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.axis([1,len(history.history[\"loss\"]), 0., 1])\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856629e9",
   "metadata": {},
   "source": [
    "## 1.6  Evaluate the Model\n",
    "1. Use the [`evaluate()`](https://keras.io/guides/training_with_built_in_methods/) method to evaluate the model on the test set.\n",
    "   * What is the performance of the model on the test set? `[1.2265034914016724, 0.6013000011444092]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b69d51",
   "metadata": {},
   "source": [
    "2. Write a function with the following signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, X, keepdims=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (keras.Model): a keras model\n",
    "        X (np.ndarray): input data\n",
    "        keepdims (bool, optional): If True, the output tensor has rank 2, otherwise rank 1\n",
    "    Returns: the predications for X either as (batch_size,) or (batch_size, 1)\n",
    "    \"\"\"\n",
    "    # My code here\n",
    "    preds = model.predict(X)\n",
    "    return preds.argmax(axis=1,keepdims=keepdims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b8290d",
   "metadata": {},
   "source": [
    "3. Use the method above to check the accuracy of the model on the validation set by comparing the output of this method to `y_valid`.\n",
    "   * You should recognize this number from the output produced by the `fit()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "prediction = get_prediction(model, x_val, keepdims=True)\n",
    "print(\"Prediction shape: \", prediction.shape)\n",
    "print(\"Prediction: \")\n",
    "print(prediction[:10])\n",
    "print(\"Validation: \")\n",
    "print(y_val[:10])\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_val, prediction)\n",
    "print(\"Validation accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b1e0fd",
   "metadata": {},
   "source": [
    "4. Write a function that identifies incorrectly classified images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77874f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incorrectly_predicted_images(model, X, y_true):\n",
    "    \"\"\"\n",
    "    model: the trained model\n",
    "    X: tensor of shape (n,image_shape), the images\n",
    "    y_true: actual labels (n,1) (or(n,))\n",
    "    Returns: three tensors of shape(m,image_shape),(m,),(m,)\n",
    "                incorrectly_classified_images, predicted_labels, expected_labels\n",
    "    \"\"\"\n",
    "    #YOUR CODE HER\n",
    "    #? Flatten y_true to ensure it is `1D`\n",
    "    print(\"y_true shape before flatten: \", y_true.shape)\n",
    "    y_true = y_true.flatten()\n",
    "    print(\"y_true shape after flatten: \", y_true.shape)\n",
    "    #? Get predictions\n",
    "    y_preds = get_prediction(model, X, keepdims=False)\n",
    "    incorrect_idx = np.where(y_preds != y_true)[0]\n",
    "    return X[incorrect_idx], y_preds[incorrect_idx], y_true[incorrect_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c571b",
   "metadata": {},
   "source": [
    "5. Apply the above function to the test set and plot a 5 by 5 grid showing 25 wrongly classified images. Show both the predicted and the actual classabove each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_images = get_incorrectly_predicted_images(model,X_test,y_test)\n",
    "print(\"Number of incorrectly classified images: \", wrong_images[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c93225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#? First 25 wrongly classified images\n",
    "images = wrong_images[0][:25]\n",
    "preds = wrong_images[1][:25]\n",
    "true = wrong_images[2][:25]\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(25):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(images[i])\n",
    "    ax.set_title(f\"Pred: {preds[i]}\\nTrue: {true[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1cd935",
   "metadata": {},
   "source": [
    "6. Finally, use a tensorflow method to create a confusion matrix for the test set. The rows should contain the actual classes, the columns are the predicted classes. Use the code below to display [the confusion matrix](https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e9d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "cm = tf.math.confusion_matrix(\n",
    "    y_test,\n",
    "    get_prediction(model, X_test, keepdims=False),\n",
    "    num_classes=None,\n",
    "    weights=None,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=None\n",
    ")\n",
    "ax = plt.subplot()\n",
    "#* annot=True to annotate cells, ftm=\"g\" to disable scientific notation\n",
    "sns.heatmap(cm, annot=True, fmt=\"g\", ax=ax, cbar=False);\n",
    "\n",
    "#* labels, title and ticks\n",
    "ax.set_xlabel(\"Predicted labels\");\n",
    "ax.set_ylabel(\"True labels\");\n",
    "ax.set_title(\"Confusion Matrix\");\n",
    "ax.xaxis.set_ticklabels(class_names, rotation=-45);\n",
    "ax.yaxis.set_ticklabels(class_names, rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05225a26",
   "metadata": {},
   "source": [
    "## 1.7  Try to Improve the Model\n",
    "Try to improve the model (i.e. try to achieve a higher accuracy). Things you could try:\n",
    "- Add an additional convolutional block.\n",
    "- Add dropout to the network to prevent overfitting. See Chapter 11.\n",
    "- Try different initialization of the weights.\n",
    "- Try to continue the training with a decreased learning rate.\n",
    "- Use Monte Carlo dropout to make predictions.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da3839",
   "metadata": {},
   "source": [
    "# 2  Practicing with the Functional API and the Layerclass\n",
    "## 2.1  Implementing a Residual Unit\n",
    "On page 515 of the book you can see an implementation of theResidualUnitclass, which is a core component of the ResNet architecture. In the book a classis created which is a subclass of thekeras.layers.Layerclass. For your con-venience, this code is reproduced in Figure1. Note thatLayeris subclassed andnotModel, because our intention is to use the class as part of a larger model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60230fc",
   "metadata": {},
   "source": [
    "### 2.1.1  Rewrite ResidualUnit as a Method using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52a16580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3,\n",
    "                        strides=1,\n",
    "                        padding=\"same\",\n",
    "                        kernel_initializer=\"he_normal\",\n",
    "                        use_bias=False)\n",
    "\n",
    "def residual_unit(input_, filters, strides=1, activation=\"relu\"):\n",
    "    activation_layer = keras.activations.get(activation)\n",
    "\n",
    "    temp_out = input_\n",
    "    main = DefaultConv2D(filters,strides=strides)(input_)\n",
    "\n",
    "    main = keras.layers.BatchNormalization()(main)\n",
    "    main = activation_layer(main)\n",
    "    main = DefaultConv2D(filters)(main)\n",
    "    main = keras.layers.BatchNormalization()(main)\n",
    "\n",
    "    skip = temp_out\n",
    "    if strides >= 2:\n",
    "        skip = DefaultConv2D(filters,kernel_size=1,strides=strides)(input_)\n",
    "        skip = keras.layers.BatchNormalization()(skip)\n",
    "\n",
    "    return activation_layer(main + skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea474fa1",
   "metadata": {},
   "source": [
    "This method should do exactly the same as the (call method of the) ResidualUnitclass. Check that the code indeed behaves identically by completing the code in Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c9a5f",
   "metadata": {},
   "source": [
    "### 2.1.2  Write a method that returns a Model.\n",
    "Complete the following method, which performs (once more) the same computation as the ResidualUnitclass but wraps this computation inside a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b75b24a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same\n",
      "valid\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "#* Partial functie geeft een object terug waar je zelf nog parameters aan kan toevoegen\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3,\n",
    "                        strides=1,\n",
    "                        padding=\"same\",\n",
    "                        kernel_initializer=\"he_normal\",\n",
    "                        use_bias=False)\n",
    "conv1 = DefaultConv2D(filters=32)\n",
    "#* Zonder partial moet je alles zelf meegeven\n",
    "conv2 = keras.layers.Conv2D(filters=32, kernel_size=3)\n",
    "\n",
    "print(conv1.padding)\n",
    "print(conv2.padding)\n",
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [DefaultConv2D(filters, strides=strides),keras.layers.BatchNormalization(),\n",
    "        self.activation,DefaultConv2D(filters),keras.layers.BatchNormalization()\n",
    "        ]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
    "                keras.layers.BatchNormalization()\n",
    "                ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        return self.activation(Z + skip_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc9afe81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">294</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">294</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_unit_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualUnit</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">294</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">294</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5531904</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_83 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m294\u001b[0m, \u001b[38;5;34m294\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m9,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_unit_33 (\u001b[38;5;33mResidualUnit\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m294\u001b[0m, \u001b[38;5;34m294\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m74,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5531904\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,712</span> (327.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,712\u001b[0m (327.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,456</span> (326.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m83,456\u001b[0m (326.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(300,300,3)))\n",
    "model.add(keras.layers.Conv2D(filters=64,\n",
    "                          kernel_size=7))\n",
    "\n",
    "model.add(ResidualUnit(filters=64))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7a9c890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300, 300, 50)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_shape = np.ones(shape=(1,300,300,50))\n",
    "test_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c3e2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_shape[:5][:5]\n",
    "test_tensor = keras.ops.array(test_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bcecfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru = ResidualUnit(filters=64)\n",
    "#* We callen onze residual unit op het test tensor\n",
    "output = ResidualUnit(filters=64,strides=1)\n",
    "# print(\"Output shape: \", output(test_tensor).shape)\n",
    "\n",
    "#! Blijft (1, 300, 300, 64) zoals verwacht, omdat we geen convolutie doen met stride>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45f69c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 150, 150, 50])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_unit(test_tensor,filters=50,strides=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0d6dfad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SHAPE = (128,128,50)\n",
    "model1 = keras.Sequential([\n",
    "    keras.layers.Input(shape=TEST_SHAPE),\n",
    "    ResidualUnit(filters=50)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "41bea0af",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ResidualUnit.__init__() got multiple values for argument 'filters'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m input_ = keras.layers.Input(shape=TEST_SHAPE)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m output_ = \u001b[43mResidualUnit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m(input_)\n\u001b[32m      3\u001b[39m model2 = keras.Model(inputs=input_, outputs=output_)\n",
      "\u001b[31mTypeError\u001b[39m: ResidualUnit.__init__() got multiple values for argument 'filters'"
     ]
    }
   ],
   "source": [
    "input_ = keras.layers.Input(shape=TEST_SHAPE)\n",
    "output_ = ResidualUnit(input_, filters=50)(input_)\n",
    "model2 = keras.Model(inputs=input_, outputs=output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model1 = model1(test_tensor)\n",
    "output_model2 = model2(test_tensor)\n",
    "keras.ops.isclose(output_model1, output_model2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
